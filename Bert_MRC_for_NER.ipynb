{"cells":[{"cell_type":"markdown","metadata":{"id":"LLKjTRd95i8G"},"source":["# 라이브러리"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15140,"status":"ok","timestamp":1707747955137,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"sG8C-s315S6d","outputId":"81b6a535-a330-4d72-c3a7-4c3d549db138"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting datasets\n","  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Collecting pyarrow>=12.0.0 (from datasets)\n","  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 10.0.1\n","    Uninstalling pyarrow-10.0.1:\n","      Successfully uninstalled pyarrow-10.0.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"6xfQI7F-5n0I"},"source":["# 코랩 마운트"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23593,"status":"ok","timestamp":1707747989119,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"kGZE8juv5q9l","outputId":"32ae103a-28cf-42e6-9a63-d281866c9bd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"JE4w05vf5yqT"},"source":["# 데이터\n","- KLUE NER Data : https://klue-benchmark.com/tasks/69/data/download\n","    - 구글 Drive에 업로드하여 사용"]},{"cell_type":"markdown","metadata":{"id":"5Eo2hQnD7MqE"},"source":["## 1. hugging face klue(허깅 페이스에도 데이터셋이 업로드 되어 있는 것을 사용)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGlWLOjq50yY"},"outputs":[],"source":["from datasets import load_dataset\n","from pprint import pprint\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285,"referenced_widgets":["471a3fc1aad14123bf2fff9762a14c7d","f7bf2e0ab8384b7ea0e8f982367b12a7","8c26597f3c3e4667bbdd6afa13e5e4fe","ece8dfb733714d23a21090917df09124","9a2bd5bcb3714d5da9887a964bd49dda","654d2a19b1fd407e8a33b726e8a323dd","687bcf468ca543c4a6352fe849c99a01","fae676f6f99f4f4995d10fcce6804440","a95cda38e8b24c75957fed6144b2b622","d38d551358964724b3de2ae5dd1f6af3","5c5f116c98304e1cac473fa3005bf436","aed3b1958dda467baa7e42ce595a09e4","f97d36f501bb46ecaffaec81a9bea080","be6bbb42ea2a4a00b573fcc8c73f580c","51345c71cb0240f78abfdb6c2dea2194","73fda8d877cc46e1a32cc688bddab7ce","19d91af2a4f34f469becd27f55d84b9d","727eee58ef014b20952910c7c7e6424b","5a7aa75a72ae4201975ec315f645d537","5dbaa132b8cb4a5882020f4cf8896324","93546135280e40918b50d35d43f86b37","67f9d97371d544aa8ed29f20787095d0","3f951f38535545978aff8e62849fe36e","bffe4df19a85471f8f494dfeaa528f8f","2208f6dc91e64baaa0d28fa2891e7259","1dde1882458a48d1bf3cc9e9c75f8e17","86cad67f6e794efe832d59ddd819ee1a","f126e8b11afb4b85a59a4a365068514e","9f97adb5755a491586fc3ac8a8d64dcb","8cbfde68f83e4a0e88ef3d0dda783408","63b4b83c5b7d48bfaedb850b66b364ee","d67951876deb465095e67dee85dec734","2fb42134824749f98000c8633ef8a0cc","2e2df427dd8143fbb90c86900e6c8a57","fc3c0f1d87c14b318f392645aeb6162e","37255f57f0674f628a62bec305907a65","ee926ee0b7b048a384373926e7c872ce","25f4baf2ffdc4045b249daff55a07a0f","21ae61942ec843ce8186aae149f08e4b","8a5cadc329bf4da8980a9696e54577d0","7e376bbc100c4755bcc2e52839eb808b","2c094201530b4dcf8317a8a2b1083449","332256d10c144eb0a2c13f3345aba99a","bc9689399805461481b7a6db9ed6bfbb","647b5a2ee72444d29ba32de71fecd4b2","a22cb1bdfa1a468aa0a3bcf83e7af7a4","73fad0e35d8e4fad90ed9cb3f48d2abc","19e08235353a4e6aa9d983cbd863f929","460910a220a7441c945821e5e72c2e42","49e5e8bf54f4494f9713d3b7dd13b856","14fb0748a60b40908761eca37bd17a32","5ce7f53597354726a0fbac5eabdc1b71","d559ea1100de41a4a299e7613ecc69b1","2400d202b019400fb38e458610312e42","ed4d2bb0f55f43a8afe314e69103da4a"]},"executionInfo":{"elapsed":3602,"status":"ok","timestamp":1707378627828,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"ty_j-k4e50vB","outputId":"203feb49-967b-4358-a753-46763a9b94af"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"471a3fc1aad14123bf2fff9762a14c7d","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aed3b1958dda467baa7e42ce595a09e4","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/4.21M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f951f38535545978aff8e62849fe36e","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e2df427dd8143fbb90c86900e6c8a57","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/21008 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"647b5a2ee72444d29ba32de71fecd4b2","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/5000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset('klue', 'ner', split='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1707378627828,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"LmZCYA9i7UfR","outputId":"0f826c3d-12b8-4c59-ca75-daac008f0d7a"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['sentence', 'tokens', 'ner_tags'],\n","    num_rows: 21008\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1707378627828,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"_67Ir8r950ry","outputId":"f082df5e-fccc-4d64-9807-04b0d6d7eaf7"},"outputs":[{"data":{"text/plain":["{'description': '',\n"," 'citation': '',\n"," 'homepage': '',\n"," 'license': '',\n"," 'features': {'sentence': Value(dtype='string', id=None),\n","  'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n","  'ner_tags': Sequence(feature=ClassLabel(names=['B-DT', 'I-DT', 'B-LC', 'I-LC', 'B-OG', 'I-OG', 'B-PS', 'I-PS', 'B-QT', 'I-QT', 'B-TI', 'I-TI', 'O'], id=None), length=-1, id=None)},\n"," 'post_processed': None,\n"," 'supervised_keys': None,\n"," 'task_templates': None,\n"," 'builder_name': 'parquet',\n"," 'dataset_name': 'klue',\n"," 'config_name': 'ner',\n"," 'version': 0.0.0,\n"," 'splits': {'train': SplitInfo(name='train', num_bytes=20035765, num_examples=21008, shard_lengths=None, dataset_name='klue'),\n","  'validation': SplitInfo(name='validation', num_bytes=4973295, num_examples=5000, shard_lengths=None, dataset_name='klue')},\n"," 'download_checksums': {'hf://datasets/klue@349481ec73fff722f88e0453ca05c77a447d967c/ner/train-00000-of-00001.parquet': {'num_bytes': 4209983,\n","   'checksum': None},\n","  'hf://datasets/klue@349481ec73fff722f88e0453ca05c77a447d967c/ner/validation-00000-of-00001.parquet': {'num_bytes': 1055904,\n","   'checksum': None}},\n"," 'download_size': 5265887,\n"," 'post_processing_size': None,\n"," 'dataset_size': 25009060,\n"," 'size_in_bytes': 30274947}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataset.info.__dict__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1707378627828,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"1OJMQjln68cz","outputId":"7b0e1953-82a6-448a-8eae-208b6fc0ec68"},"outputs":[{"name":"stdout","output_type":"stream","text":["특히 <영동고속도로:LC> <강릉:LC> 방향 <문막휴게소:LC>에서 <만종분기점:LC>까지 <5㎞:QT> 구간에는 승용차 전용 임시 갓길차로제를 운영하기로 했다.\n","['특', '히', ' ', '영', '동', '고', '속', '도', '로', ' ', '강', '릉', ' ', '방', '향', ' ', '문', '막', '휴', '게', '소', '에', '서', ' ', '만', '종', '분', '기', '점', '까', '지', ' ', '5', '㎞', ' ', '구', '간', '에', '는', ' ', '승', '용', '차', ' ', '전', '용', ' ', '임', '시', ' ', '갓', '길', '차', '로', '제', '를', ' ', '운', '영', '하', '기', '로', ' ', '했', '다', '.']\n","[12, 12, 12, 2, 3, 3, 3, 3, 3, 12, 2, 3, 12, 12, 12, 12, 2, 3, 3, 3, 3, 12, 12, 12, 2, 3, 3, 3, 3, 12, 12, 12, 8, 9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n"]}],"source":["print(dataset[0]['sentence'])\n","print(dataset[0]['tokens'])\n","print(dataset[0]['ner_tags'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1707378627828,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"ll8kbO0T7bg8","outputId":"fee733dd-73e5-480e-8033-5a5ed714831c"},"outputs":[{"name":"stdout","output_type":"stream","text":["특 12\n","히 12\n","- 12\n","영 2\n","동 3\n","고 3\n","속 3\n","도 3\n","로 3\n","- 12\n","강 2\n","릉 3\n","- 12\n","방 12\n","향 12\n","- 12\n","문 2\n","막 3\n","휴 3\n","게 3\n","소 3\n","에 12\n","서 12\n","- 12\n","만 2\n","종 3\n","분 3\n","기 3\n","점 3\n","까 12\n","지 12\n","- 12\n","5 8\n","㎞ 9\n","- 12\n","구 12\n","간 12\n","에 12\n","는 12\n","- 12\n","승 12\n","용 12\n","차 12\n","- 12\n","전 12\n","용 12\n","- 12\n","임 12\n","시 12\n","- 12\n","갓 12\n","길 12\n","차 12\n","로 12\n","제 12\n","를 12\n","- 12\n","운 12\n","영 12\n","하 12\n","기 12\n","로 12\n","- 12\n","했 12\n","다 12\n",". 12\n"]}],"source":["for token, tag in zip(dataset[0]['tokens'], dataset[0]['ner_tags']):\n","    if token == ' ':\n","        token = '-'\n","    print(token, tag)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1707378629573,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"fFKDcBaY8gm1","outputId":"d5aad4c4-81ec-403c-cfd6-f46f39eac603"},"outputs":[{"data":{"text/plain":["['B-DT',\n"," 'I-DT',\n"," 'B-LC',\n"," 'I-LC',\n"," 'B-OG',\n"," 'I-OG',\n"," 'B-PS',\n"," 'I-PS',\n"," 'B-QT',\n"," 'I-QT',\n"," 'B-TI',\n"," 'I-TI',\n"," 'O']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset.features['ner_tags'].feature.names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707378629870,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"6hcc5gn39aJH","outputId":"a0748c85-17f1-4a3c-bc70-ccc600211a74"},"outputs":[{"data":{"text/plain":["{0: 'B-DT',\n"," 1: 'I-DT',\n"," 2: 'B-LC',\n"," 3: 'I-LC',\n"," 4: 'B-OG',\n"," 5: 'I-OG',\n"," 6: 'B-PS',\n"," 7: 'I-PS',\n"," 8: 'B-QT',\n"," 9: 'I-QT',\n"," 10: 'B-TI',\n"," 11: 'I-TI',\n"," 12: 'O'}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["label_list = dataset.features['ner_tags'].feature.names\n","id_to_label = {i:label for i, label in enumerate(label_list)}\n","id_to_label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1707378631480,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"Vqn2SP9M95Bp","outputId":"e28f7e98-37e7-4637-c59f-516a3043e7bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["특 O 12\n","히 O 12\n","- O 12\n","영 B-LC 2\n","동 I-LC 3\n","고 I-LC 3\n","속 I-LC 3\n","도 I-LC 3\n","로 I-LC 3\n","- O 12\n","강 B-LC 2\n","릉 I-LC 3\n","- O 12\n","방 O 12\n","향 O 12\n","- O 12\n","문 B-LC 2\n","막 I-LC 3\n","휴 I-LC 3\n","게 I-LC 3\n","소 I-LC 3\n","에 O 12\n","서 O 12\n","- O 12\n","만 B-LC 2\n","종 I-LC 3\n","분 I-LC 3\n","기 I-LC 3\n","점 I-LC 3\n","까 O 12\n","지 O 12\n","- O 12\n","5 B-QT 8\n","㎞ I-QT 9\n","- O 12\n","구 O 12\n","간 O 12\n","에 O 12\n","는 O 12\n","- O 12\n","승 O 12\n","용 O 12\n","차 O 12\n","- O 12\n","전 O 12\n","용 O 12\n","- O 12\n","임 O 12\n","시 O 12\n","- O 12\n","갓 O 12\n","길 O 12\n","차 O 12\n","로 O 12\n","제 O 12\n","를 O 12\n","- O 12\n","운 O 12\n","영 O 12\n","하 O 12\n","기 O 12\n","로 O 12\n","- O 12\n","했 O 12\n","다 O 12\n",". O 12\n"]}],"source":["for token, tag in zip(dataset[0]['tokens'], dataset[0]['ner_tags']):\n","    if token == ' ':\n","        token = '-'\n","    print(token, id_to_label[tag], tag)"]},{"cell_type":"markdown","metadata":{"id":"t_v6J5Eh_fUf"},"source":["## KLUE Bert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317,"referenced_widgets":["891ac8ae7fe2427eb4193ad8a3a8c988","d553fbdcae474cbcaa52d320448c5ebc","dc78e90e846945f8b9fac6d0f2a599a6","789215b74b864eeb902f454722716792","913341fd949148749656968aaf4c4c31","dc8c0a38c663491dabd36e03ac49be3c","56844b8157a54ef88cb21b8d6433598f","13451417ef224b2883e4d7685008e4c6","46ec58009ee14c4e93418dc16c0f10e5","7f0762d52579469dbe161c4631f46f7c","138448d36e2749c6bb666b09aa7e812f","eeea8078f9f94179aa12b0d1112b4608","5cc18342112b4e61bc01a0eb82703983","7eb428de431d46fea5638628d762fef4","9b3a6baa5ff64fdbb7b86c2b0bb940b7","81f519e4eb044532be1e04e36cc0214f","77b650fa6c2345ca805795d886197d90","2b17c4d429334fa6a67f3f511d7f4d55","aaebd545194c4598a2aeab4b52638d44","69348750f066461d8149db40992d1514","fe5f0712bb724f858575ab3a6be0f7ae","e389c53ba7fb41239b30e751572f4b7e","cff18aae18814fcfae52846a1411099b","b1769221179c40dab957ef0ed9d76526","7240c5704ff64d45bc1a71d4a204a6c5","52f334fdfd6b4f3c880c17d8961791c1","7237a0e7878946559daa2653c27e247c","f15d6556839a41199422b19ddd925a43","2b049029bd044fd2be6f0bf72ac64edf","8abcaabacf594539b6249d4e9e4f9ddf","adcc65538b0c4933bb942df1c868c3dc","0964a98b8508481384758cb9229c7068","29f8ecf5928545b583784034fffff83a","0cd88d64316e4ae68555823fb0531bb6","657d338701cb47c687318c51ece4bd27","3840c97ae55642e9ba3005727934601c","0f1201b0ed67453db9e60401bd1405fa","a9e0deaec6a74f36893927978d91d1a1","a333e0dd584e4bb2aae21b1d7739b47d","58ddacda7a01434da8dfd8c94513857c","8469a71422024eaabdbfd04de97e0ca0","f0d7ad968e334ac5af1bbb829d76b887","7ae4e616ce2b4b39bcc7fc81206bce38","1d9683936e424b8c882bc6b333a8cda9","26ee635c97844d7b9ecfbef1a1fb38d9","5d066da7cd3d4971b606b27293ac9818","570bb3b2e56f409fb5a530da5c5d8050","11364373241c475b811c78cb76eacd7c","b4ed130b9920481a84c44924af691dce","a922d1d72bee470fbda5fa8bae602421","5884861489734c97b360b184bb09d465","c943bc7f00f544c48afa21df8bdc77cf","96cf6557c162480d9ac27a87bd6d3800","15e34ce77a6247118798054dd1f59e60","5e5eaf41e6764e378ee9f1b88069a6fd","dada57c9c7ba489dbd7cd9ed30dac2a7","1c7674cf1fca4ffb877544cf0bfe0a09","63d24a794ec24e16bc5ccd7339d23f31","1e33ac94ae8747f69510d37490dd577e","7f38df42c483403dbb664c56091adb5b","87ac88d9a788432387617ab8a1f8eb81","6fd966f6b4e5473fb2500685df82623f","eb64f4cdfa1f42e8abb88bd09fa55dcb","7660fc9a40cd4485865d0f1dad467331","e62a428f660a48b5b74d610dd163b986","3c1d0ff16d45460ab9e5214c9c111ae0"]},"executionInfo":{"elapsed":13860,"status":"ok","timestamp":1707660598729,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"u12ExzeE-NhF","outputId":"3f0ca3d6-f5c3-4697-b0ad-27bdbdafa189"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"891ac8ae7fe2427eb4193ad8a3a8c988","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eeea8078f9f94179aa12b0d1112b4608","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cff18aae18814fcfae52846a1411099b","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cd88d64316e4ae68555823fb0531bb6","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26ee635c97844d7b9ecfbef1a1fb38d9","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dada57c9c7ba489dbd7cd9ed30dac2a7","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n","model = AutoModel.from_pretrained('klue/bert-base')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707378653635,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"Qm91Cepx_3Bm","outputId":"12f4921a-651c-4169-fb84-5b16d641168d"},"outputs":[{"data":{"text/plain":["['수학',\n"," 'A',\n"," '##형',\n"," '##의',\n"," '1',\n"," '##등',\n"," '##급',\n"," '커트',\n"," '##라인',\n"," '##은',\n"," '평균',\n"," '96',\n"," '##점',\n"," ',',\n"," '수학',\n"," 'B',\n"," '##형',\n"," '##은',\n"," '99',\n"," '##점',\n"," '##이',\n"," '##었',\n"," '##다',\n"," '.']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# ex\n","text = '수학 A형의 1등급 커트라인은 평균 96점, 수학 B형은 99점이었다.'\n","tokenizer.tokenize(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707378653635,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"vJTtHRymAEwU","outputId":"f2fdef78-8066-4a48-c23e-fab74d2a5597"},"outputs":[{"data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9z2EpB0AT_8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"JOF5nKHCAlZi"},"source":["## 2. KLUE base data 사용\n","- KLUE NER Data : https://klue-benchmark.com/tasks/69/data/download\n","    - data\n","    - baseline code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1707378660678,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"F_ym8yhoC5Mr","outputId":"82bb8f44-c801-4c2d-9ecc-a916b36c8c3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner_code\n"]}],"source":["%cd /content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner_code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1707378662225,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"HiCqs7WeC-jw","outputId":"083f9b9d-4f14-4f70-df56-f9b84456ade1"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset.py  inference.py  model  model.py  requirements.txt  utils.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mR5wcdzAlMk"},"outputs":[],"source":["# KLUE dataset.py 사용\n","\n","from typing import Dict, List, Union\n","\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizer\n","\n","\n","class CollateNer(object):\n","    def __init__(\n","        self, tokenizer: PreTrainedTokenizer, label2idx: Dict[str, int], max_length: int\n","    ):\n","        self.tokenizer = tokenizer\n","        self.label2idx = label2idx\n","        self.max_length = max_length\n","\n","    def __call__(self, input_examples):\n","        input_texts, input_labels_str = [], []\n","        for input_example in input_examples:\n","            text, label_strs = input_example\n","            input_texts.append(text)\n","            input_labels_str.append(label_strs)\n","\n","        encoded_texts = self.tokenizer.batch_encode_plus(\n","            input_texts,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            truncation=True,\n","            padding=\"max_length\",  # KLUE 베이스라인과 input형태를 일치 시키기 위해\n","            return_tensors=\"pt\",\n","            return_token_type_ids=True,\n","            return_attention_mask=True,\n","        )\n","        input_ids = encoded_texts[\"input_ids\"]\n","        token_type_ids = encoded_texts[\"token_type_ids\"]\n","        attention_mask = encoded_texts[\"attention_mask\"]\n","\n","        len_input = input_ids.size(1)\n","        input_labels = []\n","        for input_label_str in input_labels_str:\n","            input_label_str = (\n","                [\"O\"] + input_label_str + (len_input - len(input_label_str) - 1) * [\"O\"]\n","            )\n","            input_label = [self.label2idx[x] for x in input_label_str]\n","            input_label = torch.tensor(input_label).long()\n","            input_labels.append(input_label)\n","\n","        input_labels = torch.stack(input_labels)\n","        \n","        return input_ids, token_type_ids, attention_mask, input_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NerDataset(Dataset):\n","    def __init__(\n","        self,\n","        tokenizer: PreTrainedTokenizer,\n","        dataset: List[Dict[str, Union[str, List[str]]]],\n","        label_list: List[str],\n","        max_length: int,\n","        batch_size: int = None,\n","        shuffle: bool = False,\n","        **kwargs\n","    ):\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","        self.label2idx = {label: i for i, label in enumerate(label_list)}\n","        self.collate_fn = CollateNer(tokenizer, self.label2idx, max_length)\n","        self.loader = DataLoader(\n","            self,\n","            batch_size=batch_size,\n","            shuffle=shuffle,\n","            collate_fn=self.collate_fn,\n","            **kwargs\n","        )\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        instance = self.dataset[index]\n","        text = instance[\"text_a\"]\n","        label_strs = instance[\"label\"]\n","\n","        return text, label_strs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVazU_YGEmbw"},"outputs":[],"source":["file_path = Path('/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_dev_sample_10.tsv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1387,"status":"ok","timestamp":1707546396767,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"czFDDnF3BsyR","outputId":"ee6feb59-c3a7-4f0e-fe19-1d3d2e7541f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["('## 토큰, 레이블 구분자 : \\\\t\\n'\n"," '## 토큰 구분자 : \\\\n\\n'\n"," '## 문장 구분자 : \\\\n\\\\n\\n'\n"," '## 주석 : ##\\n'\n"," '## 컬럼명 : CHAR\\tNE_TAG\\n'\n"," '## klue-ner-v1_dev_00000-wikitree\\t<경찰:OG>은 또 성매매 알선 자금을 관리한 <박:PS>씨의 '\n"," '딸(<32:QT>)과 성매매 여성 <김:PS>모(<33:QT>)씨 등 <16명:QT>을 같은 혐의로 불구속 입건했다.\\n'\n"," '경\\tB-OG\\n'\n"," '찰\\tI-OG\\n'\n"," '은\\tO\\n'\n"," ' \\tO\\n'\n"," '또\\tO\\n'\n"," ' \\tO\\n'\n"," '성\\tO\\n'\n"," '매\\tO\\n'\n"," '매\\tO\\n'\n"," ' \\tO\\n'\n"," '알\\tO\\n'\n"," '선\\tO\\n'\n"," ' \\tO\\n'\n"," '자\\tO\\n'\n"," '금\\tO\\n'\n"," '을\\tO\\n'\n"," ' \\tO\\n'\n"," '관\\tO\\n'\n"," '리\\tO')\n"]}],"source":["file_text = file_path.read_text().strip()\n","pprint(file_text[:300])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpd9wp5KEIs6"},"outputs":[],"source":["sentences = file_text.split('\\n\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707546398738,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"wFXo5k42FBDp","outputId":"c550e3ab-62b5-4c99-d865-2a2163b68c81"},"outputs":[{"name":"stdout","output_type":"stream","text":["('## 토큰, 레이블 구분자 : \\\\t\\n'\n"," '## 토큰 구분자 : \\\\n\\n'\n"," '## 문장 구분자 : \\\\n\\\\n\\n'\n"," '## 주석 : ##\\n'\n"," '## 컬럼명 : CHAR\\tNE_TAG\\n'\n"," '## klue-ner-v1_dev_00000-wikitree\\t<경찰:OG>은 또 성매매 알선 자금을 관리한 <박:PS>씨의 '\n"," '딸(<32:QT>)과 성매매 여성 <김:PS>모(<33:QT>)씨 등 <16명:QT>을 같은 혐의로 불구속 입건했다.\\n'\n"," '경\\tB-OG\\n'\n"," '찰\\tI-OG\\n'\n"," '은\\tO\\n'\n"," ' \\tO\\n'\n"," '또\\tO\\n'\n"," ' \\tO\\n'\n"," '성\\tO\\n'\n"," '매\\tO\\n'\n"," '매\\tO\\n'\n"," ' \\tO\\n'\n"," '알\\tO\\n'\n"," '선\\tO\\n'\n"," ' \\tO\\n'\n"," '자\\tO\\n'\n"," '금\\tO\\n'\n"," '을\\tO\\n'\n"," ' \\tO\\n'\n"," '관\\tO\\n'\n"," '리\\tO\\n'\n"," '한\\tO\\n'\n"," ' \\tO\\n'\n"," '박\\tB-PS\\n'\n"," '씨\\tO\\n'\n"," '의\\tO\\n'\n"," ' \\tO\\n'\n"," '딸\\tO\\n'\n"," '(\\tO\\n'\n"," '3\\tB-QT\\n'\n"," '2\\tI-QT\\n'\n"," ')\\tO\\n'\n"," '과\\tO\\n'\n"," ' \\tO\\n'\n"," '성\\tO\\n'\n"," '매\\tO\\n'\n"," '매\\tO\\n'\n"," ' \\tO\\n'\n"," '여\\tO\\n'\n"," '성\\tO\\n'\n"," ' \\tO\\n'\n"," '김\\tB-PS\\n'\n"," '모\\tO\\n'\n"," '(\\tO\\n'\n"," '3\\tB-QT\\n'\n"," '3\\tI-QT\\n'\n"," ')\\tO\\n'\n"," '씨\\tO\\n'\n"," ' \\tO\\n'\n"," '등\\tO\\n'\n"," ' \\tO\\n'\n"," '1\\tB-QT\\n'\n"," '6\\tI-QT\\n'\n"," '명\\tI-QT\\n'\n"," '을\\tO\\n'\n"," ' \\tO\\n'\n"," '같\\tO\\n'\n"," '은\\tO\\n'\n"," ' \\tO\\n'\n"," '혐\\tO\\n'\n"," '의\\tO\\n'\n"," '로\\tO\\n'\n"," ' \\tO\\n'\n"," '불\\tO\\n'\n"," '구\\tO\\n'\n"," '속\\tO\\n'\n"," ' \\tO\\n'\n"," '입\\tO\\n'\n"," '건\\tO\\n'\n"," '했\\tO\\n'\n"," '다\\tO\\n'\n"," '.\\tO')\n"]}],"source":["pprint(sentences[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707546401810,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"orH_k4LJFD7B","outputId":"51cc9b7b-72db-4c9c-afe4-73654355a48a"},"outputs":[{"name":"stdout","output_type":"stream","text":["경찰은 또 성매매 알선 자금을 관리한 박씨의 딸(32)과 성매매 여성 김모(33)씨 등 16명을 같은 혐의로 불구속 입건했다. ['B-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","['B-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}],"source":["sentences = file_text.split('\\n\\n')\n","sentence = ''\n","char_labels = []\n","\n","for line in sentences[0].split('\\n'):\n","    if line.startswith('##'):\n","        continue\n","    token, tag = line.split('\\t')\n","    sentence += token\n","    char_labels.append(tag)\n","\n","print(sentence, char_labels)\n","print(char_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1707379003730,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"IXXFITKwKiTj","outputId":"c5251b73-ce9c-4f47-e91a-34dcb00b8732"},"outputs":[{"name":"stdout","output_type":"stream","text":["경 B-OG\n","찰 I-OG\n","은 O\n","  O\n","또 O\n","  O\n","성 O\n","매 O\n","매 O\n","  O\n","알 O\n","선 O\n","  O\n","자 O\n","금 O\n","을 O\n","  O\n","관 O\n","리 O\n","한 O\n","  O\n","박 B-PS\n","씨 O\n","의 O\n","  O\n","딸 O\n","( O\n","3 B-QT\n","2 I-QT\n",") O\n","과 O\n","  O\n","성 O\n","매 O\n","매 O\n","  O\n","여 O\n","성 O\n","  O\n","김 B-PS\n","모 O\n","( O\n","3 B-QT\n","3 I-QT\n",") O\n","씨 O\n","  O\n","등 O\n","  O\n","1 B-QT\n","6 I-QT\n","명 I-QT\n","을 O\n","  O\n","같 O\n","은 O\n","  O\n","혐 O\n","의 O\n","로 O\n","  O\n","불 O\n","구 O\n","속 O\n","  O\n","입 O\n","건 O\n","했 O\n","다 O\n",". O\n"]}],"source":["for s, l in zip(sentence, char_labels):\n","    if s == ' ':\n","        s = ' '\n","    print(s, l)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usHlKBREzeJM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aNd13gjWzeot"},"source":["## Dataset 구축\n","- 1. KLUE dataset : 음절 => Bert dataset : Bert token 단위로 변경\n","- 2. Bert Token offsets_maping으로 음절 구분"]},{"cell_type":"markdown","metadata":{"id":"W4OBz3N23NVm"},"source":["- ex"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707546406291,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"6oiUJewFt59p","outputId":"fcec50d5-6cb6-4535-bb15-6f9b5d674575"},"outputs":[{"data":{"text/plain":["[(0, 0),\n"," (0, 2),\n"," (2, 3),\n"," (4, 5),\n"," (6, 9),\n"," (10, 12),\n"," (13, 15),\n"," (15, 16),\n"," (17, 19),\n"," (19, 20),\n"," (21, 22),\n"," (22, 23),\n"," (23, 24),\n"," (25, 26),\n"," (26, 27),\n"," (27, 29),\n"," (29, 30),\n"," (30, 31),\n"," (32, 35),\n"," (36, 38),\n"," (39, 40),\n"," (40, 41),\n"," (41, 42),\n"," (42, 44),\n"," (44, 45),\n"," (45, 46),\n"," (47, 48),\n"," (49, 51),\n"," (51, 52),\n"," (52, 53),\n"," (54, 55),\n"," (55, 56),\n"," (57, 59),\n"," (59, 60),\n"," (61, 63),\n"," (63, 64),\n"," (65, 67),\n"," (67, 68),\n"," (68, 69),\n"," (69, 70),\n"," (0, 0)]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["offset_mapping = tokenizer(sentence, return_offsets_mapping=True)['offset_mapping']\n","offset_mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1707381986079,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"o-xeYyGG5YwV","outputId":"61b68e3b-5d80-45e4-9689-e70bd03f33b5"},"outputs":[{"data":{"text/plain":["['경찰',\n"," '##은',\n"," '또',\n"," '성매매',\n"," '알선',\n"," '자금',\n"," '##을',\n"," '관리',\n"," '##한',\n"," '박',\n"," '##씨',\n"," '##의',\n"," '딸',\n"," '(',\n"," '32',\n"," ')',\n"," '과',\n"," '성매매',\n"," '여성',\n"," '김',\n"," '##모',\n"," '(',\n"," '33',\n"," ')',\n"," '씨',\n"," '등',\n"," '16',\n"," '##명',\n"," '##을',\n"," '같',\n"," '##은',\n"," '혐의',\n"," '##로',\n"," '불구',\n"," '##속',\n"," '입건',\n"," '##했',\n"," '##다',\n"," '.']"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.tokenize(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707381771253,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"ThtGmC0_3Kyu","outputId":"6faa42b8-994f-460c-efb4-f8c06c25a3d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["경찰 B-OG\n","##은 O\n","또 O\n","성매매 O\n","알선 O\n","자금 O\n","##을 O\n","관리 O\n","##한 O\n","박 B-PS\n","##씨 O\n","##의 O\n","딸 O\n","( O\n","32 B-QT\n",") O\n","과 O\n","성매매 O\n","여성 O\n","김 B-PS\n","##모 O\n","( O\n","33 B-QT\n",") O\n","씨 O\n","등 O\n","16 B-QT\n","##명 I-QT\n","##을 O\n","같 O\n","##은 O\n","혐의 O\n","##로 O\n","불구 O\n","##속 O\n","입건 O\n","##했 O\n","##다 O\n",". O\n"]}],"source":["token_labels = []\n","offset_mapping = tokenizer(sentence, return_offsets_mapping=True)['offset_mapping']\n","for offset in offset_mapping:\n","    s, e = offset\n","    if s == e == 0:\n","        continue\n","    token_labels.append(char_labels[s])\n","\n","tokens = tokenizer.tokenize(sentence)\n","for token, label in zip(tokens, token_labels):\n","    print(token, label)"]},{"cell_type":"markdown","metadata":{"id":"9Am_vwTU_W3o"},"source":["- klue data -> bert token 화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LY85tciI8XHu"},"outputs":[],"source":["from transformers import PreTrainedTokenizer\n","from pathlib import Path\n","\n","def load_data(file_path: str, tokenizer: PreTrainedTokenizer = None):\n","    klue_data = Path(file_path)\n","    klue_text = klue_data.read_text().strip()\n","    documents = klue_text.split('\\n\\n')\n","\n","    data_list = []\n","    for doc in documents:\n","        char_labels = []\n","        token_labels = []\n","        chars = []\n","        sentence = ''\n","        for line in doc.split('\\n'):\n","            if line.startswith('##'):\n","                continue\n","            token, tag = line.split('\\t')\n","            sentence += token\n","            char_labels.append(tag)\n","            chars.append(token)\n","\n","        offset_mappings = tokenizer(sentence, return_offsets_mapping=True)['offset_mapping']\n","        for offset in offset_mappings:\n","            s, e = offset\n","            if s == e == 0:\n","                continue\n","            token_labels.append(char_labels[s])\n","\n","        instance = {\n","                    'sentence':sentence,\n","                    'token_label':token_labels,\n","                    'char_label':char_labels,\n","                    'offset_mapping':offset_mappings\n","        }\n","        data_list.append(instance)\n","\n","    return data_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFeG_X137bzl"},"outputs":[],"source":["file_path = '/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_dev_sample_10.tsv'\n","examples = load_data(file_path, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":762,"status":"ok","timestamp":1707546417741,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"sADequa2-KLn","outputId":"89517186-569c-43e0-803d-0c6f69ed3023"},"outputs":[{"data":{"text/plain":["{'sentence': '경찰은 또 성매매 알선 자금을 관리한 박씨의 딸(32)과 성매매 여성 김모(33)씨 등 16명을 같은 혐의로 불구속 입건했다.',\n"," 'token_label': ['B-OG',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'],\n"," 'char_label': ['B-OG',\n","  'I-OG',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'],\n"," 'offset_mapping': [(0, 0),\n","  (0, 2),\n","  (2, 3),\n","  (4, 5),\n","  (6, 9),\n","  (10, 12),\n","  (13, 15),\n","  (15, 16),\n","  (17, 19),\n","  (19, 20),\n","  (21, 22),\n","  (22, 23),\n","  (23, 24),\n","  (25, 26),\n","  (26, 27),\n","  (27, 29),\n","  (29, 30),\n","  (30, 31),\n","  (32, 35),\n","  (36, 38),\n","  (39, 40),\n","  (40, 41),\n","  (41, 42),\n","  (42, 44),\n","  (44, 45),\n","  (45, 46),\n","  (47, 48),\n","  (49, 51),\n","  (51, 52),\n","  (52, 53),\n","  (54, 55),\n","  (55, 56),\n","  (57, 59),\n","  (59, 60),\n","  (61, 63),\n","  (63, 64),\n","  (65, 67),\n","  (67, 68),\n","  (68, 69),\n","  (69, 70),\n","  (0, 0)]}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(examples)\n","examples[0]"]},{"cell_type":"markdown","metadata":{"id":"1o_L_IhpC-xb"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1707660614245,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"izZTtcTg-dZY","outputId":"2e7f0c40-49a3-4bc1-ff91-fff73a398aa4"},"outputs":[{"data":{"text/plain":["['B-PS',\n"," 'I-PS',\n"," 'B-LC',\n"," 'I-LC',\n"," 'B-OG',\n"," 'I-OG',\n"," 'B-DT',\n"," 'I-DT',\n"," 'B-TI',\n"," 'I-TI',\n"," 'B-QT',\n"," 'I-QT',\n"," 'O']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["labels = [\n","    'B-PS', 'I-PS',\n","    'B-LC', 'I-LC',\n","    'B-OG', 'I-OG',\n","    'B-DT', 'I-DT',\n","    'B-TI', 'I-TI',\n","    'B-QT', 'I-QT',\n","    'O',\n","]\n","labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1707660616988,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"638WpT4-DsEH","outputId":"4cf0410e-17a2-407c-d7b9-fcca9f050d04"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'B-PS': 0, 'I-PS': 1, 'B-LC': 2, 'I-LC': 3, 'B-OG': 4, 'I-OG': 5, 'B-DT': 6, 'I-DT': 7, 'B-TI': 8, 'I-TI': 9, 'B-QT': 10, 'I-QT': 11, 'O': 12}\n","{0: 'B-PS', 1: 'I-PS', 2: 'B-LC', 3: 'I-LC', 4: 'B-OG', 5: 'I-OG', 6: 'B-DT', 7: 'I-DT', 8: 'B-TI', 9: 'I-TI', 10: 'B-QT', 11: 'I-QT', 12: 'O'}\n"]}],"source":["# string label => tensor화\n","\n","label_to_id = {label:i for i, label in enumerate(labels)}\n","id_to_label = {i:label for i, label in enumerate(labels)}\n","\n","print(label_to_id)\n","print(id_to_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1707384847468,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"lNhpwE6sEHW6","outputId":"926a5407-60c0-4660-8a88-f1989f1f50f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner_code\n"]}],"source":["%cd /content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner_code\n","\n","from dataset import CollateNer, NerDataset"]},{"cell_type":"markdown","metadata":{"id":"OzBRRNyEM6HC"},"source":["### collate fn  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":661,"status":"ok","timestamp":1707546819684,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"qjokh5pnHY_c","outputId":"e49df7e8-8463-49d1-e49e-1a091ba3c06b"},"outputs":[{"name":"stdout","output_type":"stream","text":["경찰은 또 성매매 알선 자금을 관리한 박씨의 딸(32)과 성매매 여성 김모(33)씨 등 16명을 같은 혐의로 불구속 입건했다.\n","['B-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'B-QT', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'B-QT', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}],"source":["print(examples[0]['sentence'])\n","print(examples[0]['token_label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":840,"status":"ok","timestamp":1707546823895,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"UNVxInVNHe2Z","outputId":"c9c9a5cf-3edf-45b3-d23f-8edaa86e5aa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," 'input_ids': tensor([[    2,  3858,  2073,   918, 12070, 15570,  4248,  2069,  3759,  2470,\n","          1119,  2483,  2079,   900,    12,  4987,    13,   604, 12070,  3811,\n","           648,  2391,    12,  5013,    13,  1370,   886,  3879,  2211,  2069,\n","           555,  2073,  4456,  2200,  4784,  2354, 11499,  2371,  2062,    18,\n","             3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n"," 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}],"source":["# ex\n","max_length = 120\n","encoded_texts = tokenizer.encode_plus(\n","    examples[0]['sentence'],\n","    add_special_tokens=True,\n","    max_length=max_length,\n","    truncation=True,\n","    padding='max_length',\n","    return_tensors='pt',\n","    return_token_type_ids=True,\n","    return_attention_mask=True\n",")\n","pprint(encoded_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":831,"status":"ok","timestamp":1707546827564,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"mWpAsP68LNMV","outputId":"b9a89957-81ac-4270-b84d-50ea82b2f803"},"outputs":[{"data":{"text/plain":["[4,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 0,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 10,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 0,\n"," 12,\n"," 12,\n"," 10,\n"," 12,\n"," 12,\n"," 12,\n"," 10,\n"," 11,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12]"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# label str -> index\n","[label_to_id[x] for x in examples[0]['token_label']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jH-dlDOrIUCp"},"outputs":[],"source":["input_label_id = [label_to_id[x] for x in examples[0]['token_label']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707546834327,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"wQo0FNkALfhA","outputId":"64c9e3e0-83c2-4da3-da3a-5576123789b6"},"outputs":[{"data":{"text/plain":["[-100,\n"," 4,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 0,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 10,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 0,\n"," 12,\n"," 12,\n"," 10,\n"," 12,\n"," 12,\n"," 12,\n"," 10,\n"," 11,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100]"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# pad\n","input_label = [-100] + input_label_id + (max_length - len(input_label_id)-1) * [-100]\n","input_label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707546839420,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"stBc3CQOLvkA","outputId":"749d41d7-c73a-4bdf-9294-5b52ca98d358"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-100,    4,   12,   12,   12,   12,   12,   12,   12,   12,    0,   12,\n","          12,   12,   12,   10,   12,   12,   12,   12,    0,   12,   12,   10,\n","          12,   12,   12,   10,   11,   12,   12,   12,   12,   12,   12,   12,\n","          12,   12,   12,   12, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])\n"]}],"source":["# tensor화\n","input_label = torch.tensor(input_label).long()\n","pprint(input_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLbkVg8jMqaK"},"outputs":[],"source":["# collate fn\n","\n","def collate_fn(input_examples):\n","    '''\n","    - 입력 문장 -> tokenizer token index 변환\n","    - 입력 label을 label index 변환\n","    - pad 처리\n","    - tensor로 변환\n","    '''\n","    input_texts, input_labels_str = [], []\n","    offset_mappings = []\n","    char_labels = []\n","    for input_example in input_examples:\n","        text, label_strs = input_example[\"sentence\"], input_example[\"token_label\"]\n","        input_texts.append(text)\n","        input_labels_str.append(label_strs)\n","        offset_mappings.append(input_example[\"offset_mapping\"])\n","        char_labels.append(input_example[\"char_label\"])\n","\n","    encoded_texts = tokenizer.batch_encode_plus(\n","        input_texts,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\",\n","        return_token_type_ids=True,\n","        return_attention_mask=True,\n","        return_offsets_mapping=True\n","    )\n","    input_ids = encoded_texts[\"input_ids\"]\n","    token_type_ids = encoded_texts[\"token_type_ids\"]\n","    attention_mask = encoded_texts[\"attention_mask\"]\n","\n","    len_input = input_ids.size(1)\n","    input_labels = []\n","    for input_label_str in input_labels_str:\n","        input_label = [label_to_id[x] for x in input_label_str]\n","        if len(input_label) > max_length - 2:\n","            input_label = input_label[:max_length - 2]\n","            input_label = [-100] + input_label + [-100]\n","        else:\n","            input_label = (\n","                [-100] + input_label + (max_length - len(input_label_str) - 1) * [-100]\n","            )\n","        input_label = torch.tensor(input_label).long()\n","        input_labels.append(input_label)\n","\n","    input_labels = torch.stack(input_labels)\n","    return input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1707546845924,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"jaLZl1wgNBHl","outputId":"89e9d40e-326e-4c48-ae08-05f232c3888f"},"outputs":[{"data":{"text/plain":["(tensor([[    2,  3858,  2073,   918, 12070, 15570,  4248,  2069,  3759,  2470,\n","           1119,  2483,  2079,   900,    12,  4987,    13,   604, 12070,  3811,\n","            648,  2391,    12,  5013,    13,  1370,   886,  3879,  2211,  2069,\n","            555,  2073,  4456,  2200,  4784,  2354, 11499,  2371,  2062,    18,\n","              3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n"," tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," tensor([[-100,    4,   12,   12,   12,   12,   12,   12,   12,   12,    0,   12,\n","            12,   12,   12,   10,   12,   12,   12,   12,    0,   12,   12,   10,\n","            12,   12,   12,   10,   11,   12,   12,   12,   12,   12,   12,   12,\n","            12,   12,   12,   12, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]),\n"," [[(0, 0),\n","   (0, 2),\n","   (2, 3),\n","   (4, 5),\n","   (6, 9),\n","   (10, 12),\n","   (13, 15),\n","   (15, 16),\n","   (17, 19),\n","   (19, 20),\n","   (21, 22),\n","   (22, 23),\n","   (23, 24),\n","   (25, 26),\n","   (26, 27),\n","   (27, 29),\n","   (29, 30),\n","   (30, 31),\n","   (32, 35),\n","   (36, 38),\n","   (39, 40),\n","   (40, 41),\n","   (41, 42),\n","   (42, 44),\n","   (44, 45),\n","   (45, 46),\n","   (47, 48),\n","   (49, 51),\n","   (51, 52),\n","   (52, 53),\n","   (54, 55),\n","   (55, 56),\n","   (57, 59),\n","   (59, 60),\n","   (61, 63),\n","   (63, 64),\n","   (65, 67),\n","   (67, 68),\n","   (68, 69),\n","   (69, 70),\n","   (0, 0)]],\n"," [['B-OG',\n","   'I-OG',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'B-PS',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'B-QT',\n","   'I-QT',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'B-PS',\n","   'O',\n","   'O',\n","   'B-QT',\n","   'I-QT',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'B-QT',\n","   'I-QT',\n","   'I-QT',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O']])"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["collate_fn(examples[:1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1707546851463,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"1c5gKlxjNNhG","outputId":"1605e177-9a3e-4521-c307-e0b78fa10196"},"outputs":[{"data":{"text/plain":["{'sentence': '경찰은 또 성매매 알선 자금을 관리한 박씨의 딸(32)과 성매매 여성 김모(33)씨 등 16명을 같은 혐의로 불구속 입건했다.',\n"," 'token_label': ['B-OG',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'],\n"," 'char_label': ['B-OG',\n","  'I-OG',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-PS',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-QT',\n","  'I-QT',\n","  'I-QT',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'],\n"," 'offset_mapping': [(0, 0),\n","  (0, 2),\n","  (2, 3),\n","  (4, 5),\n","  (6, 9),\n","  (10, 12),\n","  (13, 15),\n","  (15, 16),\n","  (17, 19),\n","  (19, 20),\n","  (21, 22),\n","  (22, 23),\n","  (23, 24),\n","  (25, 26),\n","  (26, 27),\n","  (27, 29),\n","  (29, 30),\n","  (30, 31),\n","  (32, 35),\n","  (36, 38),\n","  (39, 40),\n","  (40, 41),\n","  (41, 42),\n","  (42, 44),\n","  (44, 45),\n","  (45, 46),\n","  (47, 48),\n","  (49, 51),\n","  (51, 52),\n","  (52, 53),\n","  (54, 55),\n","  (55, 56),\n","  (57, 59),\n","  (59, 60),\n","  (61, 63),\n","  (63, 64),\n","  (65, 67),\n","  (67, 68),\n","  (68, 69),\n","  (69, 70),\n","  (0, 0)]}"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["examples[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vbMrZ0eNNeI"},"outputs":[],"source":["# dataset\n","\n","class NerDataset(Dataset):\n","    def __init__(\n","        self,\n","        tokenizer: PreTrainedTokenizer,\n","        examples: List,\n","        shuffle: bool = False,\n","        **kwargs\n","    ):\n","        self.dataset = examples\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        instance = self.dataset[index]\n","\n","        return instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPDxRyhiQxhu"},"outputs":[],"source":["file_path = '/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_dev_sample_10.tsv'\n","examples = load_data(file_path, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mW1-ASdWQ7cF"},"outputs":[],"source":["dataset = NerDataset(tokenizer=tokenizer, examples=examples, max_length=config.max_seq_len)\n","dataloader = DataLoader(dataset, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707548037348,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"2E_SFndsSImQ","outputId":"3524b711-2699-408c-fd9c-bb1360d1419b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[    2,  3727, 30032,  7825,  4367,  1091,  2395,  2198,  2318,  2024,\n","         27135,  1038,  2033,  2377,  2015,  2532,  2299,  2118,    25,  2038,\n","          2037,  5757,  2170,  2259,  8960,  5119,  5937,   551,  2454,  2232,\n","          2200,  2021,  2138,  3792, 31302,  2200,  1902,  2062,    18,     3,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n"," tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," tensor([[-100,   12,    2,    2,   12,    2,    3,    3,    3,    3,   12,    2,\n","            3,    3,    3,    3,   12,   12,   10,   11,   11,   12,   12,   12,\n","           12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n","           12,   12,   12, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]),\n"," [[(0, 0),\n","   (0, 2),\n","   (3, 9),\n","   (10, 12),\n","   (13, 15),\n","   (16, 17),\n","   (17, 18),\n","   (18, 19),\n","   (19, 20),\n","   (20, 21),\n","   (21, 23),\n","   (24, 25),\n","   (25, 26),\n","   (26, 27),\n","   (27, 28),\n","   (28, 29),\n","   (29, 30),\n","   (30, 31),\n","   (32, 33),\n","   (33, 34),\n","   (34, 35),\n","   (36, 38),\n","   (38, 39),\n","   (39, 40),\n","   (41, 44),\n","   (45, 47),\n","   (48, 50),\n","   (51, 52),\n","   (52, 53),\n","   (53, 54),\n","   (54, 55),\n","   (55, 56),\n","   (56, 57),\n","   (58, 60),\n","   (60, 62),\n","   (62, 63),\n","   (64, 65),\n","   (65, 66),\n","   (66, 67),\n","   (0, 0)]],\n"," [['O',\n","   'O',\n","   'O',\n","   'B-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'O',\n","   'B-LC',\n","   'I-LC',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'B-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'O',\n","   'O',\n","   'O',\n","   'B-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'I-LC',\n","   'O',\n","   'O',\n","   'O',\n","   'B-QT',\n","   'I-QT',\n","   'I-QT',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O',\n","   'O']])\n"]}],"source":["for batch in dataloader:\n","    pprint(batch)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707548039953,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"fyt8xIxRSOkK","outputId":"4f329885-92d0-437c-febd-62833aacc5b6"},"outputs":[{"data":{"text/plain":["120"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["len(batch[0][0])"]},{"cell_type":"markdown","metadata":{"id":"WCmGVzycTQPG"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwVNkgcsTQFr"},"outputs":[],"source":["import torch\n","from dataclasses import dataclass\n","from transformers import PreTrainedTokenizer, BertConfig, BertForTokenClassification\n","\n","@dataclass\n","class Config():\n","    model_name: str = 'klue/bert-base'\n","    train_data: str = '/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_train.tsv'\n","    test_data: str = '/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_dev.tsv'\n","    epoch: int = 3\n","    device: str = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    max_seq_len: int = 510\n","    batch_size: int = 24\n","    learning_rate: float = 1e-3\n","    adam_epsilon: float = 1e-8\n","    max_grad_norm: float = 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707660885593,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"V_v_MZukWyT1","outputId":"2afc5b23-1a69-4768-b75f-975d9c1514af"},"outputs":[{"data":{"text/plain":["Config(model_name='klue/bert-base', train_data='/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_train.tsv', test_data='/content/drive/MyDrive/NLP_Dataset/KLUE-NER/klue-ner-v1.1/klue-ner-v1.1_dev.tsv', epoch=3, device=device(type='cuda'), max_seq_len=510, batch_size=24, learning_rate=0.001, adam_epsilon=1e-08, max_grad_norm=1.0)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["init_config = Config()\n","init_config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707660885594,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"7WpIWT4fW141","outputId":"20b48e6e-fa27-4f0b-c316-94d2c7f9be94"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'klue/bert-base'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["init_config.model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nl7VxMkOW7H_"},"outputs":[],"source":["config = BertConfig.from_pretrained(init_config.model_name, num_labels=len(label_to_id))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsLo8hWVXST7"},"outputs":[],"source":["config.update(init_config.__dict__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707660886579,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"nwIKIyR-Xw7Z","outputId":"0e6541c1-7687-4cbb-e73f-aa82d5784117"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'klue/bert-base'"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["config.model_name"]},{"cell_type":"markdown","metadata":{"id":"45bG6zj5Zf1l"},"source":["### train/valid dataset 구성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZ6cc7cCZjUD"},"outputs":[],"source":["examples = load_data(init_config.train_data, tokenizer)\n","index = int(len(examples) * 0.1)\n","max_length = config.max_seq_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUaO4qQrZjRA"},"outputs":[],"source":["# dataset\n","train_dataset = NerDataset(tokenizer, examples[:index])\n","valid_dataset = NerDataset(tokenizer, examples[index:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tF0jUuwSZjOI"},"outputs":[],"source":["# dataloader\n","train_loader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n","valid_loader = DataLoader(dataset=valid_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZ7hj2ocvMmj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"DcOJVuGBY7wQ"},"source":["# Modeling"]},{"cell_type":"markdown","metadata":{"id":"n7G_Gwm_ZAAQ"},"source":["## 1. Huggingface BertForTokenClassification\n","- Bert + classification\n","\n","[https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForTokenClassification](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForTokenClassification)\n","\n","[https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/bert/modeling_bert.py#L1705](https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/bert/modeling_bert.py#L1705)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":709,"status":"ok","timestamp":1707660658359,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"4DSKskriY7hB","outputId":"ed4b8b67-6d9e-4226-f8c9-cdc0341b2c88"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForTokenClassification.from_pretrained(config.model_name, config=config)\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1707660662144,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"pdVDtR-dbz84","outputId":"b0f4f272-d4b0-4917-d807-4b0cedb6704c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import AdamW\n","\n","optimizer_grouped_parameters = [\n","    {'params':model.bert.parameters(), 'lr':config.learning_rate / 100},\n","    {'params':model.classifier.parameters(), 'lr':config.learning_rate}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon)"]},{"cell_type":"markdown","metadata":{"id":"nUyGPUi7uVvl"},"source":["## Train test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1707463502587,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"hW0xPx6wu3ku","outputId":"a9f5bf9f-f952-4170-c6d4-07f825555fbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[    2,  3678,  5960,  ...,     0,     0,     0],\n","        [    2,   594, 11481,  ...,     0,     0,     0],\n","        [    2,  3671, 15209,  ...,     0,     0,     0],\n","        ...,\n","        [    2,   560, 11187,  ...,     0,     0,     0],\n","        [    2,  3995, 19301,  ...,     0,     0,     0],\n","        [    2,  3771,  2284,  ...,     0,     0,     0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,    0,    1,  ..., -100, -100, -100],\n","        [-100,    4,    5,  ..., -100, -100, -100],\n","        ...,\n","        [-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,   12,    2,  ..., -100, -100, -100],\n","        [-100,   12,   12,  ..., -100, -100, -100]]), [[(0, 0), (0, 3), (4, 6), (7, 9), (9, 10), (11, 13), (13, 14), (14, 15), (16, 17), (17, 18), (19, 21), (21, 22), (23, 25), (25, 27), (28, 30), (30, 31), (32, 34), (34, 35), (36, 38), (38, 39), (39, 40), (41, 42), (43, 44), (44, 46), (47, 49), (49, 51), (52, 54), (55, 57), (57, 58), (59, 61), (61, 62), (63, 65), (66, 69), (69, 70), (71, 73), (73, 74), (75, 77), (78, 80), (80, 81), (81, 82), (83, 85), (85, 86), (86, 87), (87, 88), (88, 90), (90, 91), (0, 0)], [(0, 0), (0, 1), (2, 5), (5, 6), (7, 9), (9, 11), (12, 14), (14, 15), (16, 18), (18, 20), (21, 24), (25, 27), (27, 29), (29, 31), (31, 33), (33, 34), (35, 37), (37, 38), (38, 39), (39, 41), (41, 42), (43, 45), (45, 47), (47, 48), (49, 51), (52, 54), (54, 56), (57, 59), (59, 60), (60, 61), (61, 62), (63, 66), (67, 69), (69, 70), (70, 71), (71, 72), (72, 73), (74, 76), (77, 79), (80, 82), (82, 83), (83, 85), (86, 88), (88, 89), (89, 90), (90, 91), (92, 94), (94, 95), (95, 96), (96, 97), (0, 0)], [(0, 0), (0, 2), (2, 4), (4, 5), (5, 6), (7, 9), (9, 10), (10, 11), (11, 12), (13, 16), (17, 19), (19, 20), (21, 22), (22, 23), (23, 25), (25, 26), (26, 27), (27, 28), (29, 31), (32, 33), (33, 34), (34, 36), (36, 37), (37, 38), (38, 39), (40, 42), (42, 43), (44, 45), (46, 48), (49, 51), (52, 54), (54, 56), (57, 59), (59, 60), (61, 63), (63, 64), (64, 66), (67, 69), (69, 70), (71, 73), (73, 74), (74, 75), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 6), (7, 8), (8, 9), (10, 12), (13, 16), (16, 18), (19, 21), (21, 22), (23, 24), (24, 28), (29, 31), (31, 32), (32, 33), (33, 34), (35, 36), (37, 39), (39, 40), (41, 45), (46, 47), (47, 48), (49, 51), (51, 52), (52, 53), (54, 56), (56, 57), (58, 60), (61, 63), (64, 66), (66, 67), (68, 69), (69, 70), (71, 73), (73, 74), (75, 77), (77, 78), (79, 81), (82, 83), (83, 84), (84, 85), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 6), (6, 7), (7, 8), (8, 9), (10, 13), (13, 14), (14, 15), (16, 19), (20, 21), (21, 22), (22, 23), (24, 25), (25, 26), (26, 28), (28, 29), (30, 32), (33, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 41), (41, 42), (0, 0)], [(0, 0), (0, 3), (4, 7), (8, 10), (11, 13), (13, 14), (15, 16), (16, 17), (18, 21), (22, 25), (25, 26), (27, 28), (28, 30), (31, 33), (33, 34), (34, 35), (35, 36), (36, 37), (38, 40), (40, 41), (42, 44), (44, 45), (45, 46), (46, 47), (0, 0)], [(0, 0), (0, 2), (2, 3), (3, 4), (4, 6), (6, 7), (8, 10), (11, 13), (13, 14), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 4), (4, 5), (5, 6), (7, 8), (8, 9), (10, 11), (11, 12), (12, 13), (14, 15), (15, 16), (16, 17), (18, 20), (20, 22), (23, 24), (24, 25), (25, 26), (27, 28), (28, 30), (30, 31), (31, 32), (32, 33), (0, 0)], [(0, 0), (0, 2), (2, 3), (3, 5), (5, 6), (6, 7), (8, 10), (11, 13), (13, 14), (15, 17), (18, 20), (20, 22), (23, 25), (26, 27), (28, 30), (30, 31), (32, 34), (35, 37), (37, 38), (39, 41), (41, 42), (43, 45), (45, 46), (46, 49), (49, 50), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 4), (4, 5), (5, 6), (7, 9), (9, 10), (11, 13), (13, 14), (14, 15), (16, 17), (17, 18), (18, 19), (19, 20), (21, 23), (23, 24), (25, 27), (27, 28), (29, 30), (30, 32), (33, 35), (35, 38), (39, 41), (42, 45), (45, 46), (46, 47), (47, 48), (48, 49), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 6), (6, 7), (8, 10), (11, 13), (14, 15), (16, 18), (18, 19), (20, 22), (22, 23), (24, 26), (26, 27), (27, 28), (28, 29), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 6), (7, 9), (9, 10), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (18, 19), (19, 20), (21, 22), (22, 24), (24, 25), (0, 0)], [(0, 0), (0, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 9), (10, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 23), (24, 25), (25, 27), (27, 28), (29, 30), (30, 31), (32, 34), (34, 35), (36, 38), (38, 39), (39, 40), (40, 41), (42, 44), (44, 45), (45, 46), (47, 49), (49, 51), (52, 53), (53, 54), (54, 55), (56, 58), (58, 59), (60, 62), (62, 63), (63, 64), (64, 66), (66, 67), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 6), (6, 7), (7, 9), (9, 10), (11, 13), (13, 14), (15, 17), (18, 19), (19, 20), (21, 23), (23, 24), (25, 28), (28, 29), (30, 31), (31, 32), (32, 33), (34, 36), (36, 37), (38, 40), (0, 0)], [(0, 0), (0, 2), (3, 7), (7, 8), (9, 11), (11, 14), (14, 15), (16, 18), (18, 20), (20, 21), (21, 22), (23, 25), (25, 26), (26, 28), (28, 29), (30, 33), (33, 34), (35, 38), (39, 41), (41, 42), (43, 44), (44, 45), (46, 48), (48, 50), (51, 52), (52, 53), (53, 55), (55, 56), (56, 57), (58, 60), (60, 61), (61, 63), (63, 64), (64, 65), (65, 66), (67, 68), (68, 69), (70, 71), (71, 72), (73, 74), (74, 75), (75, 76), (76, 78), (78, 79), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 8), (8, 9), (10, 12), (12, 13), (13, 14), (14, 15), (15, 16), (17, 19), (19, 20), (20, 21), (22, 25), (25, 26), (27, 28), (28, 29), (29, 30), (0, 0)]], [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'O', 'B-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'B-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'O', 'B-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-DT', 'I-DT', 'O', 'B-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TI', 'I-TI', 'I-TI', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TI', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']])\n"]}],"source":["# input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels\n","for batch in train_loader:\n","    print(batch)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2x1fNYeuGer"},"outputs":[],"source":["import torch\n","from tqdm import tqdm, trange\n","\n","def train_epoch(model, dataloader, optimizer):\n","    model.train()\n","    total_loss = 0.0\n","    echo_loss = 0.0\n","    for batch in tqdm(dataloader):\n","        inputs = {\n","                'input_ids':batch[0].to(config.device),\n","                'token_type_ids':batch[1].to(config.device),\n","                'attention_mask':batch[2].to(config.device),\n","                'labels':batch[3].to(config.device)\n","                }\n","        outputs = model(**inputs)\n","        loss = outputs[0] # return : [loss, logits, hidden_status, attentions]\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n","        optimizer.step()\n","        total_loss += loss\n","\n","    return total_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462010,"status":"ok","timestamp":1707464728934,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"isWkfyCNum13","outputId":"73a539e1-2cde-4d38-a88a-7bf9dce125d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:47<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["1: 32.994632720947266\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["2: 6.565506935119629\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:46<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["3: 4.0615315437316895\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:46<00:00,  1.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["4: 2.7454187870025635\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["5: 1.7108429670333862\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["6: 1.2967344522476196\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["7: 1.1255788803100586\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["8: 1.0363242626190186\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:45<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["9: 0.5194812417030334\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 88/88 [00:46<00:00,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["10: 0.5607724785804749\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for epoch in range(config.epoch):\n","    train_loss = train_epoch(model, train_loader, optimizer)\n","    print(f'{epoch+1}: {train_loss}')"]},{"cell_type":"markdown","metadata":{"id":"-WV3dVzt_r-5"},"source":["-  평가 메트릭 : span 단위로 평가(하나의 sapn이 달라도 틀리도록)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7268,"status":"ok","timestamp":1707660677053,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"jB988G4Rumy5","outputId":"97b0e774-ac1e-4cf0-cece-41f5fa4f288d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=63da4c05d79ed1513d683c1bebb9ba4f9e60aedab7841b7707cd9b919afb2845\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAeLDSeLumwQ"},"outputs":[],"source":["from seqeval.metrics import accuracy_score, performance_measure\n","from seqeval.metrics import classification_report\n","from seqeval.metrics import f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707547160159,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"NXo0leeH5ktU","outputId":"1613a3e7-15b2-4c47-d3c9-7ecb5c95f94c"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        MISC       1.00      1.00      1.00         2\n","         PER       0.00      0.00      0.00         1\n","\n","   micro avg       1.00      0.67      0.80         3\n","   macro avg       0.50      0.50      0.50         3\n","weighted avg       0.67      0.67      0.67         3\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# macro avg 사용할 것\n","\n","y_true = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'B-PER', 'O'], ['B-MISC', 'I-MISC', 'O']]\n","y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O'], ['B-MISC', 'I-MISC', 'O']]\n","\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"3JNtAeV4ANjV"},"source":["### Validation test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3591,"status":"ok","timestamp":1707547281093,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"E8cTWXYEFxGm","outputId":"5fb68c7a-dd76-46c3-f043-4f256815760b"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/88 [00:03<?, ?it/s]\n"]}],"source":["for batch in tqdm(train_loader):\n","    labels = batch[3].to(config.device)\n","    inputs = {\n","            'input_ids':batch[0].to(config.device),\n","            'token_type_ids':batch[1].to(config.device),\n","            'attention_mask':batch[2].to(config.device),\n","            'labels':batch[3].to(config.device)\n","            }\n","    outputs = model(**inputs)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1707469189106,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"L7NGVLKwFxDw","outputId":"bc57fa32-087f-4195-bfec-62cd43a39228"},"outputs":[{"data":{"text/plain":["TokenClassifierOutput(loss=tensor(8.5503e-05, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[ -2.1320,  -4.2565,  -4.5778,  ...,  -3.5298,  -4.8318,  12.6265],\n","         [ 18.3002,   0.6227,  -3.0506,  ...,  -2.6469,  -6.8874,   3.8468],\n","         [  1.9716,  13.9195,  -7.2338,  ...,  -4.3229,  -1.1339,   0.7706],\n","         ...,\n","         [ -4.2968,  -5.4732,  -4.4058,  ...,  -0.8242,  -5.2317,  11.2485],\n","         [ -1.5487,  -5.2986,  -4.0157,  ...,   0.1777,  -4.7889,  10.2518],\n","         [ -1.1765,  -5.2012,  -1.3153,  ...,  -0.5087,  -4.4138,   9.7580]],\n","\n","        [[ -5.3090,  -3.6859,  -5.9407,  ...,  -4.7969,  -5.2841,  14.3458],\n","         [ -8.3820,  -6.2278,  -6.0882,  ...,  -4.2156,  -7.2529,  16.5459],\n","         [-12.3374,  -5.1012,  -9.4736,  ...,  -5.4538,  -2.3502,  15.0191],\n","         ...,\n","         [ -4.8331,  -4.4554,  -5.7324,  ...,  -2.6044,  -4.1199,  10.8474],\n","         [ -2.9739,  -4.7927,  -3.7408,  ...,  -2.3268,  -3.9850,  11.6703],\n","         [ -1.3929,  -3.6595,  -4.8039,  ...,  -3.4367,  -3.4684,  12.1790]],\n","\n","        [[ -4.2815,  -4.3789,  -4.9971,  ...,  -4.3516,  -5.9711,  13.7095],\n","         [ -6.7381,  -3.6560,  -5.9926,  ...,  -5.6082,  -6.5516,  15.2004],\n","         [ -7.8323,  -6.0593,  -4.7440,  ...,  -0.2059,  -3.9134,  12.5378],\n","         ...,\n","         [ -0.9259,  -3.7623,  -5.7219,  ...,  -3.0610,  -3.1351,  11.9455],\n","         [ -4.2957,  -3.7437,  -5.9945,  ...,  -3.5486,  -2.6620,  11.2955],\n","         [ -2.2090,  -5.3050,  -2.8960,  ...,  -2.6829,  -4.3384,  10.8939]],\n","\n","        ...,\n","\n","        [[ -1.6670,  -1.1432,  -5.1441,  ...,  -6.6185,  -5.1206,  12.2133],\n","         [ -7.2222,  -5.4261,  -8.0947,  ...,  -3.6310,  -5.9415,  15.0976],\n","         [ -2.8004,  -4.8830,  -4.5802,  ...,   0.6667,  -3.9717,   9.7308],\n","         ...,\n","         [ -1.8673,  -4.2439,  -2.9106,  ...,  -3.3943,  -3.5962,  10.5989],\n","         [ -1.9283,  -4.3811,  -3.2038,  ...,  -3.3994,  -2.9905,  11.1900],\n","         [ -3.6144,  -3.6473,  -2.2516,  ...,  -4.1770,  -2.9974,  10.5819]],\n","\n","        [[ -4.8899,  -3.9097,  -4.6119,  ...,  -4.2399,  -3.2406,  13.6022],\n","         [ -5.6972,  -8.2569,  -7.8705,  ...,  -0.8197,  -5.5403,  15.9871],\n","         [ -8.3217,  -4.4666,  -5.1267,  ...,  -3.9176,  -4.8379,  14.3251],\n","         ...,\n","         [ -4.1501,  -5.3453,  -4.6400,  ...,  -1.6790,  -2.9491,  11.5951],\n","         [ -4.2899,  -4.8546,  -5.2287,  ...,  -2.6826,  -4.5121,  12.4444],\n","         [ -3.9754,  -5.0747,  -4.2534,  ...,  -2.4491,  -6.1151,  11.5488]],\n","\n","        [[ -4.0456,  -3.7474,  -5.6731,  ...,  -2.6545,  -2.2900,  11.6781],\n","         [ -5.4947,  -6.5783,  -8.2460,  ...,  -7.1043,  -3.8183,  17.8784],\n","         [ -7.6962,  -5.7581,  -8.5724,  ...,  -4.3238,  -2.9394,  18.2698],\n","         ...,\n","         [ -2.5622,  -4.9117,  -3.3363,  ...,  -0.2735,  -2.2477,   9.9831],\n","         [ -1.6576,  -4.9817,  -4.2559,  ...,   0.0204,  -2.7549,  10.7272],\n","         [ -2.2091,  -5.9455,  -3.7443,  ...,  -0.8307,  -4.3990,  10.7657]]],\n","       device='cuda:0', grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":828,"status":"ok","timestamp":1707547291523,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"vcmjfRmZFxA8","outputId":"f14aa964-2f36-4786-ea00-ddc62c62bfb6"},"outputs":[{"data":{"text/plain":["torch.Size([24, 120, 13])"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["logits = outputs[1]\n","logits.shape # (batch_size, seq_max_length, class_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1707547295033,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"q4_4HUroFw-O","outputId":"ad193bb2-828d-4397-d1c5-7d17f46537fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0.3161, -0.6914,  1.6829, -0.3773, -1.2557, -0.1066, -0.4316, -0.3418,\n","         0.0116,  0.8806,  0.2939,  0.1701, -0.3315], grad_fn=<SliceBackward0>)\n"]},{"data":{"text/plain":["tensor([[ 2,  2,  2,  ...,  8,  2,  0],\n","        [10,  5,  3,  ...,  0, 12,  0],\n","        [ 2,  5,  0,  ...,  0,  9,  9],\n","        ...,\n","        [10,  4,  4,  ...,  9,  9,  9],\n","        [ 0,  2,  9,  ...,  9, 12, 12],\n","        [ 0,  2,  2,  ...,  0,  0,  0]])"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["print(logits[0, 0, :])\n","logits.argmax(dim=2) # predicted labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707469500068,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"WyAqu0nxG--h","outputId":"f018fe5b-a42b-427f-ca12-a7c89d01bcbb"},"outputs":[{"data":{"text/plain":["array([12,  0,  1,  1, 12,  0,  1, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12,  0,  1,  1, 12, 12,  1, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12,  0, 12, 12,  0, 12, 12,  1, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12,  0, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12,  0, 12, 12, 12,  0, 12, 12,  1, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12,  0,  0,  1, 12, 12,  1, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  0,  0, 12, 12, 12,  1,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12,  0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  0, 12, 12,\n","       12, 12, 12, 12, 12,  0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12,  0, 12,  0, 12, 12,  0,  0,  1, 12,\n","       12, 12, 12, 12,  0,  1, 12, 12,  1, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  0,  0, 12,\n","       12,  0, 12,  0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  0, 12,  1,  0,\n","       12,  0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  0, 12, 12,  0,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  1, 12, 12,\n","       12, 12])"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["token_predictions = logits.argmax(dim=2)\n","token_predictions = token_predictions.detach().cpu().numpy()\n","token_predictions[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1707470343388,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"OT5LxX9NKbhm","outputId":"b051a360-1cc0-4168-80d6-378587176e15"},"outputs":[{"data":{"text/plain":["tensor([-100,    6,    7,    7,   12,    2,   12,   12,   12,   12,   12,   12,\n","          12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100], device='cuda:0')"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["labels[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707547358356,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"mzghEfDRwNxt","outputId":"900cf6e2-fe09-4fc0-eec1-077e6a907ff3"},"outputs":[{"data":{"text/plain":["[-100,\n"," 4,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 10,\n"," 11,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," 12,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100,\n"," -100]"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["labels[0].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707547413668,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"sEPPGtaSJ3XV","outputId":"ceca5993-a7ff-43ca-f7cf-2f67fd6b2123"},"outputs":[{"data":{"text/plain":["tensor([ 2,  2,  2,  5,  0,  8,  2,  0,  5,  5,  0,  0,  7,  8,  8,  2,  5,  9,\n","         2,  2,  7,  7,  9,  5,  9, 10,  0,  0,  0,  5,  4,  2,  3, 11, 11, 11,\n","         8,  8,  8,  8,  0,  2,  0,  8,  2,  2, 12,  9, 12,  0,  0,  2,  2,  9,\n","         0,  0,  9,  9, 12,  0,  0,  9,  0,  2,  0,  8,  2,  0,  0,  2,  2,  2,\n","         0,  2,  9,  2,  9,  2,  9,  9,  9,  0,  2,  8,  2, 12,  0, 12,  0,  8,\n","         2,  2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  2,  2,  2,  9,  9,\n","         9,  9,  9,  2,  0,  0,  0,  0,  0,  8,  2,  0])"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["logits.argmax(dim=2)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1707470327493,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"Dqjb-3EZIXqi","outputId":"dd5ecf45-8a5c-4bfc-d6b5-78aa9d1ff4d1"},"outputs":[{"data":{"text/plain":["tensor([[-100,    6,    7,  ..., -100, -100, -100],\n","        [-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,    4,    5,  ..., -100, -100, -100],\n","        ...,\n","        [-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,    0,    1,  ..., -100, -100, -100],\n","        [-100,   12,   12,  ..., -100, -100, -100]], device='cuda:0')"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707469790614,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"rc3TZtlgG-jY","outputId":"b8b7c6ea-ff27-4cb4-cea1-a7777e06a6ba"},"outputs":[{"data":{"text/plain":["(torch.Size([24, 512]), torch.Size([24, 512]))"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["labels.shape, logits.argmax(dim=2).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707548314077,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"OCKzZBfez3ce","outputId":"32b852e4-ce9e-4ffd-bc22-aca6403909e5"},"outputs":[{"data":{"text/plain":["{0: 'B-PS',\n"," 1: 'I-PS',\n"," 2: 'B-LC',\n"," 3: 'I-LC',\n"," 4: 'B-OG',\n"," 5: 'I-OG',\n"," 6: 'B-DT',\n"," 7: 'I-DT',\n"," 8: 'B-TI',\n"," 9: 'I-TI',\n"," 10: 'B-QT',\n"," 11: 'I-QT',\n"," 12: 'O'}"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["id_to_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"husin79QHarx"},"outputs":[],"source":["all_token_predictions = []\n","all_token_labels = []\n","\n","for token_prediction, label in zip(token_predictions, labels):\n","    filtered = []\n","    filtered_label = []\n","    for i in range(len(token_prediction)):\n","        if label[i].tolist() == -100:\n","            continue\n","        filtered.append(id_to_label[token_prediction[i]])\n","        filtered_label.append(id_to_label[label[i].tolist()])\n","    assert len(filtered) == len(filtered_label)\n","    all_token_predictions.append(filtered)\n","    all_token_labels.append(filtered_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1707470556870,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"JnRHO39vHan_","outputId":"939e8d91-9966-4df9-a3ac-b86dadc54d55"},"outputs":[{"name":"stdout","output_type":"stream","text":["B-PS\tB-DT\n","I-PS\tI-DT\n","I-PS\tI-DT\n","O\tO\n","B-PS\tB-LC\n","I-PS\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n"]}],"source":["for token_prediction, token_label in zip(all_token_predictions[0], all_token_labels[0]):\n","    print(f\"{token_prediction}\\t{token_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFO1v9Sm_5Yq"},"outputs":[],"source":["def valid_epoch(dataloader, model):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    all_token_predictions = []\n","    all_token_labels = []\n","    for i, batch in enumerate(tqdm(dataloader)):\n","        with torch.no_grad():\n","            input_ids = batch[0].to(config.device)\n","            token_type_ids = batch[1].to(config.device)\n","            attention_mask = batch[2].to(config.device)\n","            labels = batch[3].to(config.device)\n","\n","            inputs = {\n","                \"input_ids\": input_ids,\n","                \"attention_mask\": attention_mask,\n","                \"token_type_ids\": token_type_ids,\n","                \"labels\": labels\n","            }\n","\n","            outputs = model(**inputs)\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","\n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id_to_label[token_prediction[i]])\n","                    filtered_label.append(id_to_label[label[i].tolist()])\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","\n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","\n","    return total_loss / len(dataloader),  token_f1, all_token_labels, all_token_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361293,"status":"ok","timestamp":1707471041527,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"uvSZwqew_5Vz","outputId":"2dc3179e-22fc-4007-f245-4c4377444e5f"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [05:59<00:00,  2.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","1/10 valid loss: 0.5607724785804749 valid_f1: 0.8416591830385197\n"]}],"source":["for epoch in range(config.epoch):\n","    # validation\n","    valid_loss, valid_f1, all_token_labels, all_token_predictions = valid_epoch(valid_loader, model)\n","    print(f\"\\n{epoch+1}/{config.epoch} valid loss: {train_loss} valid_f1: {valid_f1}\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1707471041527,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"_XpMl-PB_5S8","outputId":"ef7963f6-041f-4620-b952-a8dba0f66502"},"outputs":[{"name":"stdout","output_type":"stream","text":["O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","B-LC\tB-LC\n","O\tI-DT\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","B-PS\tB-PS\n","I-PS\tI-PS\n","I-PS\tI-PS\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n"]}],"source":["for label, pred in zip(all_token_labels[0], all_token_predictions[0]):\n","    print(f\"{label}\\t{pred}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8435,"status":"ok","timestamp":1707471082678,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"rz3S2yYfL4mo","outputId":"c9ae3f0e-2e5e-431c-f638-f1a9ac7eef20"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          DT       0.82      0.83      0.83      7228\n","          LC       0.75      0.72      0.73      5998\n","          OG       0.74      0.78      0.76      7596\n","          PS       0.90      0.92      0.91     13061\n","          QT       0.89      0.91      0.90     10424\n","          TI       0.90      0.93      0.92      1797\n","\n","   micro avg       0.84      0.85      0.85     46104\n","   macro avg       0.84      0.85      0.84     46104\n","weighted avg       0.84      0.85      0.85     46104\n","\n"]}],"source":["print(classification_report(all_token_labels, all_token_predictions))"]},{"cell_type":"markdown","metadata":{"id":"HNuskoUQ1LjZ"},"source":["## Character level Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707660704547,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"oCnVCUaXNPDq","outputId":"21bd2e11-a647-4f35-db68-8898a11d6bcd"},"outputs":[{"data":{"text/plain":["[(0, 0),\n"," (0, 1),\n"," (1, 2),\n"," (3, 5),\n"," (5, 7),\n"," (8, 10),\n"," (11, 13),\n"," (13, 15),\n"," (15, 17),\n"," (18, 21),\n"," (21, 22),\n"," (0, 0)]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["text = \"7일 고양에서 열린 친선경기에서 손흥민은\"\n","ex_labels = [\"B-DT\", \"I-DT\", \"B-LC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PS\", \"O\"]\n","offset_mappings = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n","offset_mappings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1707660706422,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"KuSrtyVO3nDL","outputId":"fb29507c-741a-4956-bf01-d60f09da9877"},"outputs":[{"data":{"text/plain":["[(0, 0),\n"," (0, 1),\n"," (1, 2),\n"," (3, 5),\n"," (5, 7),\n"," (8, 10),\n"," (11, 13),\n"," (13, 15),\n"," (15, 17),\n"," (18, 21),\n"," (21, 22),\n"," (0, 0)]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["offset_mappings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707660708572,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"Ccge1bCY1pLR","outputId":"d41afe7d-8d9d-4a8f-c2d1-a44d7ba04e65"},"outputs":[{"data":{"text/plain":["['7', '##일', '고양', '##에서', '열린', '친선', '##경기', '##에서', '손흥민', '##은']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.tokenize(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707660710158,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"gRZ8z63z1zoK","outputId":"766199d2-67e2-4147-b510-d04aa9c02eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["7 \t (0, 1) \t 1 \t B-DT\n","##일 \t (1, 2) \t 1 \t I-DT\n","고양 \t (3, 5) \t 2 \t B-LC\n","##에서 \t (5, 7) \t 2 \t O\n","열린 \t (8, 10) \t 2 \t O\n","친선 \t (11, 13) \t 2 \t O\n","##경기 \t (13, 15) \t 2 \t O\n","##에서 \t (15, 17) \t 2 \t O\n","손흥민 \t (18, 21) \t 3 \t B-PS\n","##은 \t (21, 22) \t 1 \t O\n"]}],"source":["for token, offset, label in zip(tokenizer.tokenize(text), offset_mappings[1:], ex_labels):\n","    s, e = offset\n","    print(token, '\\t', offset, '\\t', e-s, '\\t', label)"]},{"cell_type":"markdown","metadata":{},"source":["- token label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCTW-dig2P1P"},"outputs":[],"source":["# token level label을 char level label로 변경\n","def token_to_char_label(token_predicts, offset_mappings):\n","\n","    char_prediction = []\n","\n","    prev_end = None\n","    for token_predict, offset_mapping in zip(token_predicts, offset_mappings[1:]):\n","        start, end = offset_mapping\n","\n","        # 이전 end와 현재 start가 1개이상 차이나면 띄어쓰기를 추가한다\n","        if prev_end != None and start - prev_end > 0:\n","            char_prediction.append(\"O\") # 띄어쓰기\n","        prev_end = end\n","\n","        # 싱글 라벨\n","        if end - start == 1:\n","            char_prediction.append(token_predict)\n","            continue\n","\n","        # 멀티 라벨\n","        for i in range(end - start):\n","            if i == 0 or token_predict == \"O\":\n","                char_prediction.append(token_predict)\n","                continue\n","            char_prediction.append(\"I-\" + token_predict.split(\"-\")[1])\n","\n","    return char_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707660713259,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"ZWHe-O_f53Ql","outputId":"e3ad950f-19a4-44fe-9f8f-ab0543c2f1f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["['B-DT', 'I-DT', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O']\n"]}],"source":["char = token_to_char_label(ex_labels, offset_mappings)\n","print(char)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707660713750,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"kd7nAldI8EKb","outputId":"159f5c08-a091-4a42-ed48-dcc96a1ea2f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["7 \t B-DT\n","일 \t I-DT\n","  \t O\n","고 \t B-LC\n","양 \t I-LC\n","에 \t O\n","서 \t O\n","  \t O\n","열 \t O\n","린 \t O\n","  \t O\n","친 \t O\n","선 \t O\n","경 \t O\n","기 \t O\n","에 \t O\n","서 \t O\n","  \t O\n","손 \t B-PS\n","흥 \t I-PS\n","민 \t I-PS\n","은 \t O\n"]}],"source":["for t, c in zip(text, char):\n","    print(t, '\\t', c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDQh_zX69DJw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ycw5YxTSg_Xw"},"source":["## Evalution - test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tA_O1oZjQOX"},"outputs":[],"source":["# Batch 단위\n","\n","def token_to_char_label(token_predictions, labels, offset_mapping_batch):\n","    char_predictions = []\n","\n","    # batch 별\n","    for token_predicts, label, offset_mappings in zip(token_predictions, labels, offset_mapping_batch):\n","\n","        # SPECIAL token 제외\n","        filtered = []\n","        for i in range(len(token_predicts)):\n","            if label[i].tolist() == -100:\n","                continue\n","            filtered.append(token_predicts[i])\n","        char_prediction = []\n","\n","        # SPECIAL token 제외\n","        if offset_mappings[0][0] == 0 and offset_mappings[0][1] == 0:\n","            del offset_mappings[0]\n","        if offset_mappings[-1][0] == 0 and offset_mappings[-1][1] == 0:\n","            del offset_mappings[-1]\n","        assert len(filtered) == len(offset_mappings)\n","\n","        prev_end = None\n","        for token_predict, offset_mapping in zip(filtered, offset_mappings):\n","            start, end = offset_mapping\n","\n","            # 이전 end와 현재 start가 1개이상 차이나면 띄어쓰기를 추가한다\n","            if prev_end != None and start - prev_end > 0:\n","                char_prediction.append(\"O\") # 띄어쓰기\n","            prev_end = end\n","\n","            # 싱글 라벨\n","            if end - start == 1:\n","                label_str = id_to_label[token_predict]\n","                char_prediction.append(label_str)\n","                continue\n","\n","            # 멀티 라벨\n","            for i in range(end - start):\n","                label_str = id_to_label[token_predict]\n","                if i == 0 or label_str == \"O\":\n","                    char_prediction.append(label_str)\n","                    continue\n","                char_prediction.append(\"I-\" + label_str.split(\"-\")[1])\n","        char_predictions.append(char_prediction)\n","    return char_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7W0Edgdg_Ij"},"outputs":[],"source":["def test_epoch(dataloader, model, tokenizer):\n","    total_loss = 0.0\n","\n","    model.eval()\n","    all_char_preds = []\n","    all_char_labels = []\n","    all_token_predictions = []\n","    all_token_labels = []\n","    for i, batch in enumerate(tqdm(dataloader)):\n","        with torch.no_grad():\n","            labels = batch[3].to(config.device)\n","            offset_mappings = batch[4]\n","            char_labels = batch[5]\n","            inputs = {\n","                \"input_ids\": batch[0].to(config.device),\n","                \"attention_mask\": batch[2].to(config.device),\n","                \"token_type_ids\": batch[1].to(config.device),\n","                \"labels\": labels,\n","            }\n","\n","            outputs = model(**inputs)\n","\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","\n","            char_predictions = token_to_char_label(token_predictions, labels, offset_mappings)\n","            for j, (char_pred, char_label) in enumerate(zip(char_predictions, char_labels)):\n","                if len(char_pred) != len(char_label):\n","                    print(tokenizer.decode(batch[0][j]))\n","                    del char_predictions[j]\n","                    del char_labels[j]\n","\n","            all_char_preds.extend(char_predictions)\n","            all_char_labels.extend(char_labels)\n","\n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id_to_label[token_prediction[i]])\n","                    filtered_label.append(id_to_label[label[i].tolist()])\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","\n","    token_result = classification_report(all_token_labels, all_token_predictions)\n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","    print(token_result)\n","\n","    char_result = classification_report(all_char_labels, all_char_preds)\n","    print(char_result)\n","    \n","    char_f1 = f1_score(all_char_labels, all_char_preds)\n","\n","    return total_loss / len(dataloader), token_f1, char_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqBURme5g_Cr"},"outputs":[],"source":["examples = load_data(init_config.test_data, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFf_wS5uhbyr"},"outputs":[],"source":["test_dataset = NerDataset(\n","    tokenizer,\n","    examples,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39DiMNIzhG-0"},"outputs":[],"source":["test_dataloader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=config.batch_size,\n","    shuffle=False,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":967403,"status":"ok","timestamp":1707662707534,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"M4oBOH41hgqD","outputId":"c332b23e-e89c-4af5-b480-ecd63cc47ce9"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 98/788 [01:56<13:41,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[CLS] 29일 각 대학들이 교육부가 선정한 부실대학으로 선정되면 내년부터 해당 학교에 입학하는 신입생들이 국가장학금을 받을 수 없는 불이익을 받습니다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▎       | 186/788 [03:40<11:54,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[CLS] 상도, 허준, 대장금은 최고다. 하지만 이병훈PD 님 서동요, 는 [UNK] \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 452/788 [08:56<06:41,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["[CLS] 중심의 위치는 북위 29. 7도, 동경 135. 8도이며 오사카 ( 大 [UNK] ) 시에서 남쪽으로 약 770km 떨어진 해상에서 시속 40km의 속도로 북북동 방향으로 이동 중이다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 609/788 [12:02<03:31,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["[CLS] 이대호는 올 시즌 일본 퍼시픽리그 타격 9위, 홈런 6위, 타점 5위, 장타율 7위 ( 0. 493 ), 득점권 타율 9위 ( 0. 323 ) 를 기록했습니다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 788/788 [15:34<00:00,  1.19s/it]\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          DT       0.00      0.01      0.00      7228\n","          LC       0.01      0.17      0.02      5998\n","          OG       0.00      0.04      0.01      7596\n","          PS       0.01      0.03      0.02     13061\n","          QT       0.01      0.05      0.01     10424\n","          TI       0.00      0.01      0.00      1797\n","\n","   micro avg       0.01      0.05      0.01     46104\n","   macro avg       0.01      0.05      0.01     46104\n","weighted avg       0.01      0.05      0.01     46104\n","\n","              precision    recall  f1-score   support\n","\n","          DT       0.00      0.01      0.00      7233\n","          LC       0.01      0.30      0.02      6010\n","          OG       0.00      0.04      0.01      7681\n","          PS       0.01      0.03      0.02     13090\n","          QT       0.01      0.04      0.01     10467\n","          TI       0.00      0.01      0.00      1799\n","\n","   micro avg       0.01      0.07      0.01     46280\n","   macro avg       0.01      0.07      0.01     46280\n","weighted avg       0.01      0.07      0.01     46280\n","\n","\n","1/3 test loss: 2.820720553095571 token_f1: 0.00947053522431453 char_f1: 0.012426888871084047\n"]}],"source":["# test\n","for epoch in range(config.epoch):\n","    # Test\n","    test_loss, token_f1, char_f1 = test_epoch(test_dataloader, model, tokenizer)\n","    print(f\"\\n{epoch+1}/{config.epoch} test loss: {test_loss} token_f1: {token_f1} char_f1: {char_f1}\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"CFNNEjfiqeEN"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWXAB_1_kKNe"},"outputs":[],"source":["model.config.device\n","\n","best_f1 = 0.0\n","best_model = None\n","tepoch = trange(config.epoch, position=0, leave=True)\n","\n","for epoch in tepoch:\n","    tepoch.set_description(f'Epoch : {epoch}')\n","\n","    train_loss = train_epoch(epoch, model, train_loader, optimizer)\n","    valid_loss, token_f1 = valid_epoch(epoch, model, valid_loader, tokenizer)\n","\n","    if best_f1 < token_f1:\n","        best_f1 = token_f1\n","        best_model = model\n","\n","    tepoch.set_postfix(valid_f1=token_f1)\n","\n","test_loss, token_f1, char_f1 = test_epoch(test_dataloader, best_model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9t6QNmaTqg_3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZmP42LxvrOyc"},"source":["## 2. Bert Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNuePp5rrOjS"},"outputs":[],"source":["# 라이브러리\n","!pip -q install transformers\n","!pip -q install datasets\n","!pip -q install seqeval"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7210,"status":"ok","timestamp":1707748042162,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"vN_OZ56Ztv64","outputId":"0b37784a-ebe8-43ca-8b8b-4804942fcbb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip -q install seqeval"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":471,"status":"ok","timestamp":1707748173999,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"_7eqagKEtnsB"},"outputs":[],"source":["from tqdm import tqdm, trange\n","import numpy as np\n","from pathlib import Path\n","from pprint import pprint\n","from typing import Dict, List, Union, Optional, Tuple\n","\n","from transformers import AutoModel, AutoTokenizer, BertPreTrainedModel, BertModel, AdamW\n","from transformers import PreTrainedTokenizer, BertConfig, BertForTokenClassification\n","\n","from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n","\n","import torch\n","from torch import nn\n","from torch.nn import CrossEntropyLoss\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","from dataclasses import dataclass\n","\n","# KLUE Bert model : hugging face\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"]},{"cell_type":"markdown","metadata":{"id":"gH27L-TCvEB1"},"source":["### Config"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707748394663,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"yy3SZ7mbtnpI"},"outputs":[],"source":["@dataclass\n","class Config():\n","  model_name: str = \"klue/bert-base\"\n","  train_data: str = \"klue-ner-v1.1_train.tsv\"\n","  test_data: str = \"klue-ner-v1.1_dev.tsv\"\n","  epoch: int = 30\n","  max_seq_len: int = 150\n","  batch_size: int = 16\n","  learning_rate: float = 5e-3\n","  adam_epsilon: float = 1e-8\n","  device: str = \"cuda\"\n","  max_grad_norm: float = 1.0\n","  seed: int = 1234\n","  intermediate_hidden_size: int = 768"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":577,"status":"ok","timestamp":1707748402246,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"g4WuDKqSuqzF"},"outputs":[],"source":["init_config = Config()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1707748420137,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"jo8Il_BFvJ2Z","outputId":"32d27082-0e2a-42bd-8d0b-8ab24d885cbf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'klue/bert-base'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["max_length = init_config.max_seq_len\n","batch_size = init_config.batch_size\n","\n","torch.manual_seed(init_config.seed)\n","np.random.seed(init_config.seed)\n","\n","init_config.model_name"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1707748439171,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"2h456LNrvK8I","outputId":"d6870da7-5948-4494-b5c4-e65dde0f67b4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'klue/bert-base'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["config = BertConfig.from_pretrained(init_config.model_name)\n","config.update(init_config.__dict__)\n","config.model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeDauNlZvty3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CqGBfZ7ivuCz"},"source":["### Huggingface BertModel 기반 CRF layer 추가\n","\n","- Huggingface BertModel\n","[https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/bert/modeling_bert.py#L1705](https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/models/bert/modeling_bert.py#L1705)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1707749080818,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"XLNuzq89vS5H"},"outputs":[],"source":["START_TAG = \"<START>\"\n","STOP_TAG = \"<STOP>\"\n","PAD = \"<PAD>\"\n","\n","labels = [\n","    \"<PAD>\",\n","    \"O\",\n","    \"B-PS\",\n","    \"I-PS\",\n","    \"B-LC\",\n","    \"I-LC\",\n","    \"B-OG\",\n","    \"I-OG\",\n","    \"B-DT\",\n","    \"I-DT\",\n","    \"B-TI\",\n","    \"I-TI\",\n","    \"B-QT\",\n","    \"I-QT\",\n","    \"<START>\",\n","    \"<STOP>\"\n","]\n","\n","label_to_id = {label: i for i, label in enumerate(labels)}\n","id_to_label = {i: label for label, i in label_to_id.items()}"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707749336635,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"uI8gzb0Mv8s5"},"outputs":[],"source":["text_samples = [\"7일 고양에서 열린 친선경기에서 손흥민은\", \"경찰은 오전 3시 김모씨를 검거했다\"]\n","label_samples = [[\"B-DT\", \"I-DT\", \"B-LC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PS\", \"O\"], [\"B-OG\", \"O\", \"B-DT\", \"I-DT\", \"I-DT\", \"B-PS\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]]"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707749351517,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"yUoBLq6QyuBO"},"outputs":[],"source":["training_data = []\n","\n","for text, label in zip(text_samples, label_samples):\n","    tokenized = tokenizer.encode_plus(text)\n","    example = {\n","        \"input_ids\": torch.tensor(tokenized[\"input_ids\"]).unsqueeze(0).long().cuda(),\n","        \"attention_mask\": torch.tensor(tokenized[\"attention_mask\"]).unsqueeze(0).cuda(),\n","        \"token_type_ids\": torch.tensor(tokenized[\"token_type_ids\"]).unsqueeze(0).cuda(),\n","        \"labels\": torch.tensor([label_to_id[l] for l in label]).unsqueeze(0).long().cuda()\n","    }\n","    training_data.append(example)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1707749357757,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"SyAHSrIOyvLR"},"outputs":[],"source":["def argmax(vec):\n","    # return the argmax as a python int\n","    _, idx = torch.max(vec, 1)\n","    \n","    return idx.item()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_sequence(seq, to_ix):\n","    idxs = [to_ix[w] for w in seq]\n","    \n","    return torch.tensor(idxs, dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def log_sum_exp(vec):\n","    max_score = vec[0, argmax(vec)]\n","    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","    \n","    return max_score + \\\n","        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1707749389014,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"dsnaZOWmyzJp"},"outputs":[],"source":["def log_sum_exp_pytorch(vec: torch.Tensor) -> torch.Tensor:\n","    \"\"\"\n","    Calculate the log_sum_exp trick for the tensor.\n","    :param vec: [batchSize * from_label * to_label].\n","    :return: [batchSize * to_label]\n","    \"\"\"\n","    maxScores, idx = torch.max(vec, 1)\n","    maxScores[maxScores == -float(\"Inf\")] = 0\n","    maxScoresExpanded = maxScores.view(vec.shape[0] ,1 , vec.shape[2]).expand(vec.shape[0], vec.shape[1], vec.shape[2])\n","\n","    return maxScores + torch.log(torch.sum(torch.exp(vec - maxScoresExpanded), 1))"]},{"cell_type":"markdown","metadata":{"id":"cA3OiBlay_IX"},"source":["- 참조 : https://github.com/pytorch/tutorials/blob/master/beginner_source/nlp/advanced_tutorial.py"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1707749505159,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"E2V6Rv-Oy6x6"},"outputs":[],"source":["class BertCRF(BertPreTrainedModel):\n","\n","    def __init__(self, config, num_labels: int):\n","        super().__init__(config)\n","        self.num_labels = num_labels\n","        self.label_size = num_labels\n","        self.start_idx = label_to_id[START_TAG]\n","        self.end_idx = label_to_id[STOP_TAG]\n","        self.pad_idx = label_to_id[PAD]\n","\n","        self.bert = BertModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.position_wise = nn.Linear(config.hidden_size, num_labels)\n","\n","        # Matrix of transition parameters.  Entry i,j is the score of\n","        # transitioning *to* i *from* j. # j에서 i로\n","        self.transitions = nn.Parameter(\n","            torch.randn(self.label_size, self.label_size))\n","\n","        # These two statements enforce the constraint that we never transfer\n","        # to the start tag and we never transfer from the stop tag\n","        self.transitions.data[label_to_id[START_TAG], :] = -10000\n","        self.transitions.data[:, label_to_id[STOP_TAG]] = -10000\n","\n","\n","    def calculate_all_scores(self, features: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Calculate all scores by adding up the transition scores and emissions (from lstm).\n","        Basically, compute the scores for each edges between labels at adjacent positions.\n","        This score is later be used for forward-backward inference\n","        :param lstm_scores: emission scores.\n","        :return:\n","        \"\"\"\n","        batch_size = features.size(0)\n","        seq_len = features.size(1)\n","        scores = self.transition.view(1, 1, self.label_size, self.label_size).expand(batch_size, seq_len, self.label_size, self.label_size) + \\\n","                 features.view(batch_size, seq_len, 1, self.label_size).expand(batch_size, seq_len, self.label_size, self.label_size)\n","        return scores\n","\n","\n","    def forward_unlabeled(self, all_scores: torch.Tensor, word_seq_lens) -> torch.Tensor:\n","        \"\"\"\n","        Calculate the scores with the forward algorithm. Basically calculating the normalization term\n","        :param all_scores: (batch_size x max_seq_len x num_labels x num_labels) from (lstm scores + transition scores).\n","        :param word_seq_lens: (batch_size)\n","        :return: The score for all the possible structures.\n","        \"\"\"\n","        batch_size = all_scores.size(0)\n","        seq_len = all_scores.size(1)\n","        dev_num = all_scores.get_device()\n","        curr_dev = torch.device(f\"cuda:{dev_num}\") if dev_num >= 0 else torch.device(\"cpu\")\n","        alpha = torch.zeros(batch_size, seq_len, self.label_size, device=curr_dev)\n","\n","        alpha[:, 0, :] = all_scores[:, 0,  self.start_idx, :] ## the first position of all labels = (the transition from start - > all labels) + current emission.\n","\n","        for word_idx in range(1, seq_len):\n","            ## batch_size, self.label_size, self.label_size\n","            before_log_sum_exp = alpha[:, word_idx-1, :].view(batch_size, self.label_size, 1).expand(batch_size, self.label_size, self.label_size) + all_scores[:, word_idx, :, :]\n","            # alpha[:, word_idx, :] = log_sum_exp_pytorch(before_log_sum_exp)\n","            alpha[:, word_idx, :] = torch.logsumexp(before_log_sum_exp, dim=1)\n","\n","        ### batch_size x label_size\n","        last_alpha = torch.gather(alpha, 1, word_seq_lens.view(batch_size, 1, 1).expand(batch_size, 1, self.label_size)-1).view(batch_size, self.label_size)\n","        last_alpha += self.transition[:, self.end_idx].view(1, self.label_size).expand(batch_size, self.label_size)\n","        last_alpha = log_sum_exp_pytorch(last_alpha.view(batch_size, self.label_size, 1)).view(batch_size)\n","\n","        ## final score for the unlabeled network in this batch, with size: 1\n","        return torch.sum(last_alpha)\n","\n","\n","    def forward_labeled(self, all_scores: torch.Tensor, word_seq_lens, tags: torch.Tensor, masks: torch.Tensor) -> torch.Tensor:\n","        '''\n","        Calculate the scores for the gold instances.\n","        :param all_scores: (batch, seq_len, label_size, label_size)\n","        :param word_seq_lens: (batch, seq_len)\n","        :param tags: (batch, seq_len)\n","        :param masks: batch, seq_len\n","        :return: sum of score for the gold sequences Shape: (batch_size)\n","        '''\n","        batchSize = all_scores.shape[0]\n","        sentLength = all_scores.shape[1]\n","\n","        ## all the scores to current labels: batch, seq_len, all_from_label?\n","        currentTagScores = torch.gather(all_scores, 3, tags.view(batchSize, sentLength, 1, 1).expand(batchSize, sentLength, self.label_size, 1)).view(batchSize, -1, self.label_size)\n","        if sentLength != 1:\n","            tagTransScoresMiddle = torch.gather(currentTagScores[:, 1:, :], 2, tags[:, : sentLength - 1].view(batchSize, sentLength - 1, 1)).view(batchSize, -1)\n","        tagTransScoresBegin = currentTagScores[:, 0, self.start_idx]\n","        endTagIds = torch.gather(tags, 1, word_seq_lens.view(batchSize, 1) - 1)\n","        tagTransScoresEnd = torch.gather(self.transition[:, self.end_idx].view(1, self.label_size).expand(batchSize, self.label_size), 1,  endTagIds).view(batchSize)\n","        score = torch.sum(tagTransScoresBegin) + torch.sum(tagTransScoresEnd)\n","        if sentLength != 1:\n","            score += torch.sum(tagTransScoresMiddle.masked_select(masks[:, 1:]))\n","        return score\n","\n","\n","    def backward(self, lstm_scores: torch.Tensor, word_seq_lens: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Backward algorithm. A benchmark implementation which is ready to use.\n","        :param lstm_scores: shape: (batch_size, sent_len, label_size) NOTE: the score from LSTMs, not `all_scores` (which add up the transtiion)\n","        :param word_seq_lens: shape: (batch_size,)\n","        :return: Backward variable\n","        \"\"\"\n","        batch_size = lstm_scores.size(0)\n","        seq_len = lstm_scores.size(1)\n","        dev_num = lstm_scores.get_device()\n","        curr_dev = torch.device(f\"cuda:{dev_num}\") if dev_num >= 0 else torch.device(\"cpu\")\n","        beta = torch.zeros(batch_size, seq_len, self.label_size, device=curr_dev)\n","\n","        ## reverse the view of computing the score. we look from behind\n","        rev_score = self.transition.transpose(0, 1).view(1, 1, self.label_size, self.label_size).expand(batch_size, seq_len, self.label_size, self.label_size) + \\\n","                    lstm_scores.view(batch_size, seq_len, 1, self.label_size).expand(batch_size, seq_len, self.label_size, self.label_size)\n","\n","        ## The code below, reverse the score from [0 -> length]  to [length -> 0].  (NOTE: we need to avoid reversing the padding)\n","        perm_idx = torch.zeros(batch_size, seq_len, device=curr_dev)\n","        for batch_idx in range(batch_size):\n","            perm_idx[batch_idx][:word_seq_lens[batch_idx]] = torch.range(word_seq_lens[batch_idx] - 1, 0, -1)\n","        perm_idx = perm_idx.long()\n","        for i, length in enumerate(word_seq_lens):\n","            rev_score[i, :length] = rev_score[i, :length][perm_idx[i, :length]]\n","\n","        ## backward operation\n","        beta[:, 0, :] = rev_score[:, 0, self.end_idx, :]\n","        for word_idx in range(1, seq_len):\n","            before_log_sum_exp = beta[:, word_idx - 1, :].view(batch_size, self.label_size, 1).expand(batch_size, self.label_size, self.label_size) + rev_score[:, word_idx, :, :]\n","            beta[:, word_idx, :] = log_sum_exp_pytorch(before_log_sum_exp)\n","\n","        ## Following code is used to check the backward beta implementation\n","        last_beta = torch.gather(beta, 1, word_seq_lens.view(batch_size, 1, 1).expand(batch_size, 1, self.label_size) - 1).view(batch_size, self.label_size)\n","        last_beta += self.transition.transpose(0, 1)[:, self.start_idx].view(1, self.label_size).expand(batch_size, self.label_size)\n","        last_beta = log_sum_exp_pytorch(last_beta.view(batch_size, self.label_size, 1)).view(batch_size)\n","\n","        # This part if optionally, if you only use `last_beta`.\n","        # Otherwise, you need this to reverse back if you also need to use beta\n","        for i, length in enumerate(word_seq_lens):\n","            beta[i, :length] = beta[i, :length][perm_idx[i, :length]]\n","\n","        return torch.sum(last_beta)\n","\n","\n","    def forward(\n","            self,\n","            input_ids: Optional[torch.Tensor] = None,\n","            attention_mask: Optional[torch.Tensor] = None,\n","            token_type_ids: Optional[torch.Tensor] = None,\n","            position_ids: Optional[torch.Tensor] = None,\n","            head_mask: Optional[torch.Tensor] = None,\n","            inputs_embeds: Optional[torch.Tensor] = None,\n","            labels: Optional[torch.Tensor] = None,\n","            output_attentions: Optional[bool] = None,\n","            output_hidden_states: Optional[bool] = None,\n","            return_dict: Optional[bool] = None,\n","            masks = None,\n","            word_len = None\n","        ):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        sequence_output = self.dropout(sequence_output)\n","        emissions = self.position_wise(sequence_output)\n","        emissions = emissions.squeeze(0)\n","        attention_mask = attention_mask.squeeze(0)\n","        labels = labels.squeeze(0)\n","        emissions = emissions[1:-1]\n","        forward_score = self._forward_alg(emissions, masks=attention_mask)\n","        gold_score = self._score_sentence(emissions, labels, masks=attention_mask)\n","        path_score, best_path = self._viterbi_decode(emissions, masks=attention_mask)\n","        return forward_score - gold_score, path_score, best_path\n","\n","\n","    def viterbi_decode(self, all_scores: torch.Tensor, word_seq_lens: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Use viterbi to decode the instances given the scores and transition parameters\n","        :param all_scores: (batch_size x max_seq_len x num_labels)\n","        :param word_seq_lens: (batch_size)\n","        :return: the best scores as well as the predicted label ids.\n","               (batch_size) and (batch_size x max_seq_len)\n","        \"\"\"\n","        batchSize = all_scores.shape[0]\n","        sentLength = all_scores.shape[1]\n","        dev_num = all_scores.get_device()\n","        curr_dev = torch.device(f\"cuda:{dev_num}\") if dev_num >= 0 else torch.device(\"cpu\")\n","        scoresRecord = torch.zeros([batchSize, sentLength, self.label_size], device=curr_dev)\n","        idxRecord = torch.zeros([batchSize, sentLength, self.label_size], dtype=torch.int64, device=curr_dev)\n","        mask = torch.ones_like(word_seq_lens, dtype=torch.int64, device=curr_dev)\n","        startIds = torch.full((batchSize, self.label_size), self.start_idx, dtype=torch.int64, device=curr_dev)\n","        decodeIdx = torch.LongTensor(batchSize, sentLength).to(curr_dev)\n","\n","        scores = all_scores\n","        # scoresRecord[:, 0, :] = self.getInitAlphaWithBatchSize(batchSize).view(batchSize, self.label_size)\n","        scoresRecord[:, 0, :] = scores[:, 0, self.start_idx, :]  ## represent the best current score from the start, is the best\n","        idxRecord[:,  0, :] = startIds\n","        for wordIdx in range(1, sentLength):\n","            ### scoresIdx: batch x from_label x to_label at current index.\n","            scoresIdx = scoresRecord[:, wordIdx - 1, :].view(batchSize, self.label_size, 1).expand(batchSize, self.label_size,\n","                                                                                  self.label_size) + scores[:, wordIdx, :, :]\n","            idxRecord[:, wordIdx, :] = torch.argmax(scoresIdx, 1)  ## the best previous label idx to crrent labels\n","            scoresRecord[:, wordIdx, :] = torch.gather(scoresIdx, 1, idxRecord[:, wordIdx, :].view(batchSize, 1, self.label_size)).view(batchSize, self.label_size)\n","\n","        lastScores = torch.gather(scoresRecord, 1, word_seq_lens.view(batchSize, 1, 1).expand(batchSize, 1, self.label_size) - 1).view(batchSize, self.label_size)  ##select position\n","        lastScores += self.transition[:, self.end_idx].view(1, self.label_size).expand(batchSize, self.label_size)\n","        decodeIdx[:, 0] = torch.argmax(lastScores, 1)\n","        bestScores = torch.gather(lastScores, 1, decodeIdx[:, 0].view(batchSize, 1))\n","\n","        for distance2Last in range(sentLength - 1):\n","            lastNIdxRecord = torch.gather(idxRecord, 1, torch.where(word_seq_lens - distance2Last - 1 > 0, word_seq_lens - distance2Last - 1, mask).view(batchSize, 1, 1).expand(batchSize, 1, self.label_size)).view(batchSize, self.label_size)\n","            decodeIdx[:, distance2Last + 1] = torch.gather(lastNIdxRecord, 1, decodeIdx[:, distance2Last].view(batchSize, 1)).view(batchSize)\n","\n","        return bestScores, decodeIdx\n","\n","\n","    def _forward_alg_batch(self, feats, masks):\n","        alphas = []\n","        # for feat, mask in tqdm(zip(feats, masks), total=len(feats), desc=\"forward\"):\n","        for feat, mask in zip(feats, masks):\n","            alpha = self._forward_alg(feat, mask)\n","            alphas.append(alpha)\n","        return torch.stack(alphas)\n","\n","\n","    def _forward_alg(self, feats, masks):\n","        # Do the forward algorithm to compute the partition function\n","        init_alphas = torch.full((1, self.label_size), -10000.) # [1,5]\n","        # START_TAG has all of the score.\n","        init_alphas[0][label_to_id[START_TAG]] = 0.\n","\n","        # Wrap in a variable so that we will get automatic backprop\n","        forward_var = init_alphas.to(\"cuda\")\n","\n","        # Iterate through the sentence # 한 단어씩 이터레이트\n","        for i, feat in enumerate(feats): # 문장 단위, feat 한개는 단어\n","            alphas_t = []  # The forward tensors at this timestep\n","            if masks[i] == 0:\n","                continue\n","            for next_tag in range(self.label_size): # 태그 단위\n","                # broadcast the emission score: it is the same regardless of\n","                # the previous tag\n","                emit_score = feat[next_tag].view(\n","                    1, -1).expand(1, self.label_size) # i번째 임베딩값 을 태그 개수만큼 늘리고\n","                # the ith entry of trans_score is the score of transitioning to # 다음 태그가 i인것에 대한 transition 값\n","                # next_tag from i\n","                trans_score = self.transitions[next_tag].view(1, -1) # 5개의 태그에서 i 태그로 가는 것\n","                # The ith entry of next_tag_var is the value for the\n","                # edge (i -> next_tag) before we do log-sum-exp\n","                next_tag_var = forward_var + trans_score + emit_score       # start + 5태그 + 해당 i번째의 feature\n","                # The forward variable for this tag is log-sum-exp of all the\n","                # scores.\n","                alphas_t.append(log_sum_exp(next_tag_var).view(1))          # log sum up\n","            forward_var = torch.cat(alphas_t).view(1, -1)\n","        terminal_var = forward_var + self.transitions[label_to_id[STOP_TAG]] # 즉 각 단어의 모든 태그에 대한 정보, 즉 어떤 태그에 어떤 단어 값이 많이 저장 된다\n","        alpha = log_sum_exp(terminal_var)\n","        return alpha\n","\n","\n","    def _score_batch(self, feats, tags, masks):\n","        scores = []\n","        for feat, tag, mask in zip(feats, tags, masks):\n","            score = self._score_sentence(feat, tag, mask)\n","            scores.append(score[0])\n","        return torch.stack(scores)\n","\n","\n","    def _score_sentence(self, feats, tags, masks):\n","        # Gives the score of a provided tag sequence\n","        score = torch.zeros(1).to(\"cuda\")\n","        tags = torch.cat([torch.tensor([label_to_id[START_TAG]], dtype=torch.long).to(\"cuda\"), tags]) # 앞에 START 추가하고\n","        # tags = torch.cat([tags, torch.tensor([label_to_id[STOP_TAG]], dtype=torch.long).to(\"cuda\")])\n","        # tags = torch.cat([torch.tensor([label_to_id[START_TAG]], dtype=torch.long).to(\"cuda\"), tags]) # 앞에 START 추가하고\n","        for i, feat in enumerate(feats):\n","            if masks[i].tolist() == 0:\n","                continue\n","            score = score + \\\n","                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]] # tag 0에서 tag 1로 가는 transition값 + featr 1 값\n","        score = score + self.transitions[label_to_id[STOP_TAG], tags[-1]]\n","        return score\n","\n","\n","    def _viterbi_decode_batch(self, feats, masks):\n","        path_scores, best_paths = [], []\n","        for feat, mask in zip(feats, masks):\n","            path_score, best_path = self._viterbi_decode(feat, mask)\n","            path_scores.append(path_score)\n","            best_paths.append(best_path)\n","        return torch.stack(path_scores), best_paths\n","\n","\n","    def _viterbi_decode(self, feats, masks):\n","        backpointers = []\n","\n","        # Initialize the viterbi variables in log space\n","        init_vvars = torch.full((1, self.label_size), -10000.)\n","        init_vvars[0][label_to_id[START_TAG]] = 0\n","\n","        # forward_var at step i holds the viterbi variables for step i-1\n","        forward_var = init_vvars.to(\"cuda\")\n","        for i, feat in enumerate(feats):\n","            if masks[i] == 0:\n","                continue\n","            bptrs_t = []  # holds the backpointers for this step\n","            viterbivars_t = []  # holds the viterbi variables for this step\n","\n","            for next_tag in range(self.label_size):\n","                # next_tag_var[i] holds the viterbi variable for tag i at the\n","                # previous step, plus the score of transitioning\n","                # from tag i to next_tag.\n","                # We don't include the emission scores here because the max\n","                # does not depend on them (we add them in below)\n","                next_tag_var = forward_var + self.transitions[next_tag]\n","                best_tag_id = argmax(next_tag_var)\n","                bptrs_t.append(best_tag_id)\n","                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n","            # Now add in the emission scores, and assign forward_var to the set\n","            # of viterbi variables we just computed\n","            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n","            backpointers.append(bptrs_t)\n","\n","        # Transition to STOP_TAG\n","        terminal_var = forward_var + self.transitions[label_to_id[STOP_TAG]]\n","        best_tag_id = argmax(terminal_var)\n","        path_score = terminal_var[0][best_tag_id]\n","\n","        # Follow the back pointers to decode the best path.\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","        # Pop off the start tag (we dont want to return that to the caller)\n","        start = best_path.pop()\n","        assert start == label_to_id[START_TAG]  # Sanity check\n","        best_path.reverse()\n","\n","\n","        return path_score, best_path"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1846,"status":"ok","timestamp":1707749666438,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"DTB30D69zXFI","outputId":"fdc7343c-5345-4f09-bdc2-f5fdbf11eff7"},"outputs":[{"data":{"text/plain":["BertCRF(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (position_wise): Linear(in_features=768, out_features=16, bias=True)\n",")"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model = BertCRF(config, num_labels=len(label_to_id))\n","model.to(config.device)\n","model"]},{"cell_type":"markdown","metadata":{},"source":["- optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FXOqPfGz6yK"},"outputs":[],"source":["optimizer_grouped_parameters = [\n","    {'params': model.bert.parameters(), 'lr': 5e-3 / 100 },\n","    {'params': model.position_wise.parameters(), 'lr': 5e-3 }\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=5e-3, eps=config.adam_epsilon)"]},{"cell_type":"markdown","metadata":{},"source":["### Huggingface BertModel 기반 hidden layer 추가"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["labels = [\n","    \"B-PS\",\n","    \"I-PS\",\n","    \"B-LC\",\n","    \"I-LC\",\n","    \"B-OG\",\n","    \"I-OG\",\n","    \"B-DT\",\n","    \"I-DT\",\n","    \"B-TI\",\n","    \"I-TI\",\n","    \"B-QT\",\n","    \"I-QT\",\n","    \"O\",\n","]\n","\n","# String label값을 tensor로 변환하기 위해\n","label2id = {label: i for i, label in enumerate(labels)}\n","id2label = {i: label for label, i in label2id.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import BertPreTrainedModel, BertModel\n","\n","class BertNer(BertPreTrainedModel):\n","    \n","    def __init__(self, config, num_labels: int):\n","        super().__init__(config)\n","        self.num_labels = num_labels\n","\n","        self.bert = BertModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.hidden_layer = nn.Linear(config.hidden_size, config.intermediate_hidden_size)\n","        self.classifier = nn.Linear(config.intermediate_hidden_size, num_labels)\n","\n","\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.Tensor] = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        token_type_ids: Optional[torch.Tensor] = None,\n","        position_ids: Optional[torch.Tensor] = None,\n","        head_mask: Optional[torch.Tensor] = None,\n","        inputs_embeds: Optional[torch.Tensor] = None,\n","        labels: Optional[torch.Tensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","        masks = None\n","    ):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        hidden_feat = self.hidden_layer(sequence_output)\n","        logits = self.classifier(F.relu(hidden_feat))\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = BertForTokenClassification.from_pretrained(config.model_name, config=config)\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = BertNer(config, num_labels=len(label2id))\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Build Dataset"]},{"cell_type":"markdown","metadata":{},"source":["### Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_data(file_path: str, tokenizer: PreTrainedTokenizer = None, max_length: int = 128):\n","    klue_data = Path(file_path)\n","    klue_text = klue_data.read_text().strip()\n","    documents = klue_text.split(\"\\n\\n\")\n","\n","    data_list = []\n","    for doc in documents[:50]:\n","        char_labels = [] \n","        token_labels = []\n","        chars = []\n","        sentence = \"\"\n","        for line in doc.split(\"\\n\"):\n","            if line.startswith(\"##\"):\n","                continue\n","            token, tag = line.split(\"\\t\")\n","            sentence += token\n","            char_labels.append(tag)\n","            chars.append(token)\n","        \n","        offset_mappings = tokenizer(sentence, max_length=max_length, return_offsets_mapping=True, truncation=True)[\"offset_mapping\"]\n","        for offset in offset_mappings:\n","            start, end = offset\n","            if start == end == 0:\n","                continue\n","            token_labels.append(char_labels[start])\n","\n","        instance = {\n","            \"sentence\": sentence,\n","            \"token_label\": token_labels,\n","            \"char_label\": char_labels,\n","            \"offset_mapping\": offset_mappings\n","        }\n","        data_list.append(instance)\n","\n","    return data_list"]},{"cell_type":"markdown","metadata":{},"source":["### Train Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NerDataset(Dataset):\n","    def __init__(\n","        self,\n","        tokenizer: PreTrainedTokenizer,\n","        examples: List,\n","        shuffle: bool = False,\n","        **kwargs\n","    ):\n","        self.dataset = examples\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        instance = self.dataset[index]\n","\n","        return instance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def collate_fn(input_examples):\n","    input_texts, input_labels_str = [], []\n","    offset_mappings = []\n","    char_labels = []\n","    \n","    for input_example in input_examples:\n","        text, label_strs = input_example[\"sentence\"], input_example[\"token_label\"]\n","        input_texts.append(text)\n","        input_labels_str.append(label_strs)\n","        offset_mappings.append(input_example[\"offset_mapping\"])\n","        char_labels.append(input_example[\"char_label\"])\n","\n","    encoded_texts = tokenizer.batch_encode_plus(\n","        input_texts,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\",\n","        return_token_type_ids=True,\n","        return_attention_mask=True,\n","        return_offsets_mapping=True\n","    )\n","    \n","    input_ids = encoded_texts[\"input_ids\"]\n","    token_type_ids = encoded_texts[\"token_type_ids\"]\n","    attention_mask = encoded_texts[\"attention_mask\"]\n","\n","    len_input = input_ids.size(1)\n","    input_labels = []\n","    for input_label_str in input_labels_str:\n","        input_label = [label2id[x] for x in input_label_str]\n","        if len(input_label) > max_length - 2:\n","            input_label = input_label[:max_length - 2]\n","            input_label = [-100] + input_label + [-100]\n","        else:\n","            input_label = (\n","                [-100] + input_label + (max_length - len(input_label_str) - 1) * [-100]\n","            )\n","        input_label = torch.tensor(input_label).long()\n","        input_labels.append(input_label)\n","\n","    input_labels = torch.stack(input_labels)\n","\n","    return input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train : valid = 7 : 3\n","\n","examples = load_data(init_config.train_data, tokenizer)\n","index = int(len(examples) * 0.7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = NerDataset(\n","    tokenizer,\n","    examples[:index]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataloader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Valid dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_dataset = NerDataset(\n","    tokenizer,\n","    examples[index:]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_dataloader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# optimizer 설정\n","from transformers import AdamW\n","\n","optimizer_grouped_parameters = [\n","    {'params': model.bert.parameters(), 'lr': config.learning_rate / 100 },\n","    {'params': model.classifier.parameters(), 'lr': config.learning_rate }\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_epoch(epoch, model, dataloader, optimizer):\n","    model.train()\n","    \n","    total_loss = 0.0\n","\n","    tepoch = tqdm(dataloader, unit=\"batch\", position=1, leave=True)\n","    for batch in tepoch:\n","        tepoch.set_description(f\"Train\")\n","        model.zero_grad()\n","        \n","        input_ids = batch[0].to(config.device)\n","        token_type_ids = batch[1].to(config.device)\n","        attention_mask = batch[2].to(config.device)\n","        labels = batch[3].to(config.device)\n","\n","        inputs = {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"token_type_ids\": token_type_ids,\n","            \"labels\": labels,\n","        }\n","        \n","        outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        tepoch.set_postfix(loss=loss.mean().item())\n","        \n","    tepoch.set_postfix(loss=total_loss / len(dataloader))\n","    \n","    return total_loss / len(dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["## Validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def valid_epoch(epoch, dataloader, model, tokenizer):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    all_char_preds = []\n","    all_char_labels = []\n","    all_token_predictions = []\n","    all_token_labels = []\n","\n","    tepoch = tqdm(dataloader, unit=\"batch\", leave=False)\n","    \n","    for batch in tepoch:\n","        tepoch.set_description(f\"Valid\")\n","        with torch.no_grad():\n","            input_ids = batch[0].to(config.device)\n","            token_type_ids = batch[1].to(config.device)\n","            attention_mask = batch[2].to(config.device)\n","            labels = batch[3].to(config.device)\n","            offset_mappings = batch[4]\n","            char_labels = batch[5]\n","            inputs = {\n","                \"input_ids\": input_ids,\n","                \"token_type_ids\": token_type_ids,\n","                \"attention_mask\": attention_mask,\n","                \"labels\": labels,\n","            }\n","\n","            outputs = model(**inputs)\n","\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","\n","            char_predictions = token_to_char_label(token_predictions, labels, offset_mappings)\n","            for j, (char_pred, char_label) in enumerate(zip(char_predictions, char_labels)):\n","                if len(char_pred) != len(char_label): # unknown 문장 처리\n","                    del char_predictions[j]\n","                    del char_labels[j]\n","\n","            all_char_preds.extend(char_predictions)\n","            all_char_labels.extend(char_labels)\n","            \n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id2label[token_prediction[i]])\n","                    filtered_label.append(id2label[label[i].tolist()])\n","\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","\n","        tepoch.set_postfix(loss=loss.mean().item())\n","\n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","\n","    return total_loss / len(dataloader),  token_f1"]},{"cell_type":"markdown","metadata":{},"source":["## Token level Evaluation\n","\n","- Train: Character : token\n","- Evaluation: Token : Character"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def token_to_char_label(token_predictions, labels, offset_mapping_batch):\n","    char_predictions = []\n","    for token_predicts, label, offset_mappings in zip(token_predictions, labels, offset_mapping_batch):\n","\n","        # SPECIAL token 제외\n","        filtered = []\n","        for i in range(len(token_predicts)):\n","            if label[i].tolist() == -100:\n","                continue\n","\n","            filtered.append(token_predicts[i])\n","\n","        char_prediction = []\n","\n","        # SPECIAL token 제외\n","        if offset_mappings[0][0] == 0 and offset_mappings[0][1] == 0:\n","            del offset_mappings[0]\n","\n","        if offset_mappings[-1][0] == 0 and offset_mappings[-1][1] == 0:\n","            del offset_mappings[-1]\n","\n","        assert len(filtered) == len(offset_mappings)\n","\n","        prev_end = None\n","        for token_predict, offset_mapping in zip(filtered, offset_mappings):\n","            start, end = offset_mapping\n","\n","            # 이전 end와 현재 start가 1개이상 차이나면 띄어쓰기를 추가한다\n","            if prev_end != None and start - prev_end > 0:\n","                char_prediction.append(\"O\") # 띄어쓰기\n","                \n","            prev_end = end\n","\n","            # 싱글 라벨\n","            if end - start == 1:\n","                label_str = id2label[token_predict]\n","                char_prediction.append(label_str)\n","                continue\n","            \n","            # 멀티 라벨\n","            for i in range(end - start):\n","                label_str = id2label[token_predict]\n","                if i == 0 or label_str == \"O\":\n","                    char_prediction.append(label_str)\n","                    continue\n","\n","                char_prediction.append(\"I-\" + label_str.split(\"-\")[1])\n","                \n","        char_predictions.append(char_prediction)\n","        \n","    return char_predictions"]},{"cell_type":"markdown","metadata":{},"source":["## Test"]},{"cell_type":"markdown","metadata":{},"source":["- test epoch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_epoch(dataloader, model, tokenizer):\n","    total_loss = 0.0\n","\n","    model.eval()\n","    \n","    all_char_preds = []\n","    all_char_labels = []\n","    all_token_predictions = []\n","    all_token_labels = []\n","\n","    tepoch = tqdm(dataloader, unit=\"batch\")\n","    for batch in tepoch:\n","        tepoch.set_description(f\"Test\")\n","        \n","        with torch.no_grad():\n","            input_ids = batch[0].to(config.device)\n","            token_type_ids = batch[1].to(config.device)\n","            attention_mask = batch[2].to(config.device)\n","            labels = batch[3].to(config.device)\n","            offset_mappings = batch[4]\n","            char_labels = batch[5]\n","\n","            inputs = {\n","                \"input_ids\": input_ids,\n","                \"attention_mask\": attention_mask,\n","                \"token_type_ids\": token_type_ids,\n","                \"labels\": labels,\n","            }\n","\n","            outputs = model(**inputs)\n","\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","\n","            char_predictions = token_to_char_label(token_predictions, labels, offset_mappings)\n","            for j, (char_pred, char_label) in enumerate(zip(char_predictions, char_labels)):\n","                if len(char_pred) != len(char_label):\n","                    # print(tokenizer.decode(batch[0][j]))\n","                    del char_predictions[j]\n","                    del char_labels[j]\n","\n","            all_char_preds.extend(char_predictions)\n","            all_char_labels.extend(char_labels)\n","            \n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id2label[token_prediction[i]])\n","                    filtered_label.append(id2label[label[i].tolist()])\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","\n","            tepoch.set_postfix(loss=loss.mean().item())\n","    \n","    token_result = classification_report(all_token_labels, all_token_predictions)\n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","    char_result = classification_report(all_char_labels, all_char_preds)\n","    char_f1 = f1_score(all_char_labels, all_char_preds, average=\"macro\")\n","\n","    print(token_result)\n","    print(char_result)\n","\n","    tepoch.set_postfix(loss=total_loss / len(dataloader), token_f1=token_f1, char_f1=char_f1)\n","    \n","    return total_loss / len(dataloader), token_f1, char_f1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["examples = load_data(init_config.test_data, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_dataset = NerDataset(\n","    tokenizer,\n","    examples,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_dataloader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"markdown","metadata":{},"source":["- training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.to(\"cuda\")\n","\n","best_f1 = 0.0\n","best_model = None \n","\n","tepoch = trange(config.epoch, position=0, leave=True)\n","for epoch in tepoch:\n","    tepoch.set_description(f\"Epoch {epoch}\")\n","\n","    train_loss = train_epoch(epoch, model, train_dataloader, optimizer)\n","    valid_loss, token_f1 = valid_epoch(epoch, valid_dataloader, model, tokenizer)\n","\n","    if best_f1 < token_f1:\n","        best_f1 = token_f1\n","        best_model = model\n","\n","    tepoch.set_postfix(valid_f1=token_f1)\n","\n","test_loss, token_f1, char_f1 = test_epoch(test_dataloader, model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0964a98b8508481384758cb9229c7068":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cd88d64316e4ae68555823fb0531bb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_657d338701cb47c687318c51ece4bd27","IPY_MODEL_3840c97ae55642e9ba3005727934601c","IPY_MODEL_0f1201b0ed67453db9e60401bd1405fa"],"layout":"IPY_MODEL_a9e0deaec6a74f36893927978d91d1a1"}},"0f1201b0ed67453db9e60401bd1405fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ae4e616ce2b4b39bcc7fc81206bce38","placeholder":"​","style":"IPY_MODEL_1d9683936e424b8c882bc6b333a8cda9","value":" 495k/495k [00:00&lt;00:00, 667kB/s]"}},"11364373241c475b811c78cb76eacd7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e34ce77a6247118798054dd1f59e60","placeholder":"​","style":"IPY_MODEL_5e5eaf41e6764e378ee9f1b88069a6fd","value":" 125/125 [00:00&lt;00:00, 10.8kB/s]"}},"13451417ef224b2883e4d7685008e4c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138448d36e2749c6bb666b09aa7e812f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14fb0748a60b40908761eca37bd17a32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15e34ce77a6247118798054dd1f59e60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19d91af2a4f34f469becd27f55d84b9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19e08235353a4e6aa9d983cbd863f929":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2400d202b019400fb38e458610312e42","placeholder":"​","style":"IPY_MODEL_ed4d2bb0f55f43a8afe314e69103da4a","value":" 5000/5000 [00:00&lt;00:00, 74612.63 examples/s]"}},"1c7674cf1fca4ffb877544cf0bfe0a09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87ac88d9a788432387617ab8a1f8eb81","placeholder":"​","style":"IPY_MODEL_6fd966f6b4e5473fb2500685df82623f","value":"model.safetensors: 100%"}},"1d9683936e424b8c882bc6b333a8cda9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dde1882458a48d1bf3cc9e9c75f8e17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d67951876deb465095e67dee85dec734","placeholder":"​","style":"IPY_MODEL_2fb42134824749f98000c8633ef8a0cc","value":" 1.06M/1.06M [00:00&lt;00:00, 4.57MB/s]"}},"1e33ac94ae8747f69510d37490dd577e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e62a428f660a48b5b74d610dd163b986","placeholder":"​","style":"IPY_MODEL_3c1d0ff16d45460ab9e5214c9c111ae0","value":" 445M/445M [00:00&lt;00:00, 475MB/s]"}},"21ae61942ec843ce8186aae149f08e4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2208f6dc91e64baaa0d28fa2891e7259":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cbfde68f83e4a0e88ef3d0dda783408","max":1055904,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63b4b83c5b7d48bfaedb850b66b364ee","value":1055904}},"2400d202b019400fb38e458610312e42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f4baf2ffdc4045b249daff55a07a0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ee635c97844d7b9ecfbef1a1fb38d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d066da7cd3d4971b606b27293ac9818","IPY_MODEL_570bb3b2e56f409fb5a530da5c5d8050","IPY_MODEL_11364373241c475b811c78cb76eacd7c"],"layout":"IPY_MODEL_b4ed130b9920481a84c44924af691dce"}},"29f8ecf5928545b583784034fffff83a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b049029bd044fd2be6f0bf72ac64edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b17c4d429334fa6a67f3f511d7f4d55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c094201530b4dcf8317a8a2b1083449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e2df427dd8143fbb90c86900e6c8a57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc3c0f1d87c14b318f392645aeb6162e","IPY_MODEL_37255f57f0674f628a62bec305907a65","IPY_MODEL_ee926ee0b7b048a384373926e7c872ce"],"layout":"IPY_MODEL_25f4baf2ffdc4045b249daff55a07a0f"}},"2fb42134824749f98000c8633ef8a0cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"332256d10c144eb0a2c13f3345aba99a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37255f57f0674f628a62bec305907a65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e376bbc100c4755bcc2e52839eb808b","max":21008,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c094201530b4dcf8317a8a2b1083449","value":21008}},"3840c97ae55642e9ba3005727934601c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8469a71422024eaabdbfd04de97e0ca0","max":494860,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0d7ad968e334ac5af1bbb829d76b887","value":494860}},"3c1d0ff16d45460ab9e5214c9c111ae0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f951f38535545978aff8e62849fe36e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bffe4df19a85471f8f494dfeaa528f8f","IPY_MODEL_2208f6dc91e64baaa0d28fa2891e7259","IPY_MODEL_1dde1882458a48d1bf3cc9e9c75f8e17"],"layout":"IPY_MODEL_86cad67f6e794efe832d59ddd819ee1a"}},"460910a220a7441c945821e5e72c2e42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ec58009ee14c4e93418dc16c0f10e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"471a3fc1aad14123bf2fff9762a14c7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7bf2e0ab8384b7ea0e8f982367b12a7","IPY_MODEL_8c26597f3c3e4667bbdd6afa13e5e4fe","IPY_MODEL_ece8dfb733714d23a21090917df09124"],"layout":"IPY_MODEL_9a2bd5bcb3714d5da9887a964bd49dda"}},"49e5e8bf54f4494f9713d3b7dd13b856":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51345c71cb0240f78abfdb6c2dea2194":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93546135280e40918b50d35d43f86b37","placeholder":"​","style":"IPY_MODEL_67f9d97371d544aa8ed29f20787095d0","value":" 4.21M/4.21M [00:00&lt;00:00, 9.04MB/s]"}},"52f334fdfd6b4f3c880c17d8961791c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0964a98b8508481384758cb9229c7068","placeholder":"​","style":"IPY_MODEL_29f8ecf5928545b583784034fffff83a","value":" 248k/248k [00:00&lt;00:00, 505kB/s]"}},"56844b8157a54ef88cb21b8d6433598f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"570bb3b2e56f409fb5a530da5c5d8050":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c943bc7f00f544c48afa21df8bdc77cf","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96cf6557c162480d9ac27a87bd6d3800","value":125}},"5884861489734c97b360b184bb09d465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58ddacda7a01434da8dfd8c94513857c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a7aa75a72ae4201975ec315f645d537":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5f116c98304e1cac473fa3005bf436":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cc18342112b4e61bc01a0eb82703983":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77b650fa6c2345ca805795d886197d90","placeholder":"​","style":"IPY_MODEL_2b17c4d429334fa6a67f3f511d7f4d55","value":"config.json: 100%"}},"5ce7f53597354726a0fbac5eabdc1b71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d066da7cd3d4971b606b27293ac9818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a922d1d72bee470fbda5fa8bae602421","placeholder":"​","style":"IPY_MODEL_5884861489734c97b360b184bb09d465","value":"special_tokens_map.json: 100%"}},"5dbaa132b8cb4a5882020f4cf8896324":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e5eaf41e6764e378ee9f1b88069a6fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63b4b83c5b7d48bfaedb850b66b364ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63d24a794ec24e16bc5ccd7339d23f31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb64f4cdfa1f42e8abb88bd09fa55dcb","max":445000316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7660fc9a40cd4485865d0f1dad467331","value":445000316}},"647b5a2ee72444d29ba32de71fecd4b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a22cb1bdfa1a468aa0a3bcf83e7af7a4","IPY_MODEL_73fad0e35d8e4fad90ed9cb3f48d2abc","IPY_MODEL_19e08235353a4e6aa9d983cbd863f929"],"layout":"IPY_MODEL_460910a220a7441c945821e5e72c2e42"}},"654d2a19b1fd407e8a33b726e8a323dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"657d338701cb47c687318c51ece4bd27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a333e0dd584e4bb2aae21b1d7739b47d","placeholder":"​","style":"IPY_MODEL_58ddacda7a01434da8dfd8c94513857c","value":"tokenizer.json: 100%"}},"67f9d97371d544aa8ed29f20787095d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"687bcf468ca543c4a6352fe849c99a01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69348750f066461d8149db40992d1514":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fd966f6b4e5473fb2500685df82623f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7237a0e7878946559daa2653c27e247c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7240c5704ff64d45bc1a71d4a204a6c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8abcaabacf594539b6249d4e9e4f9ddf","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adcc65538b0c4933bb942df1c868c3dc","value":248477}},"727eee58ef014b20952910c7c7e6424b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73fad0e35d8e4fad90ed9cb3f48d2abc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ce7f53597354726a0fbac5eabdc1b71","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d559ea1100de41a4a299e7613ecc69b1","value":5000}},"73fda8d877cc46e1a32cc688bddab7ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7660fc9a40cd4485865d0f1dad467331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77b650fa6c2345ca805795d886197d90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"789215b74b864eeb902f454722716792":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f0762d52579469dbe161c4631f46f7c","placeholder":"​","style":"IPY_MODEL_138448d36e2749c6bb666b09aa7e812f","value":" 289/289 [00:00&lt;00:00, 27.3kB/s]"}},"7ae4e616ce2b4b39bcc7fc81206bce38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e376bbc100c4755bcc2e52839eb808b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb428de431d46fea5638628d762fef4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaebd545194c4598a2aeab4b52638d44","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69348750f066461d8149db40992d1514","value":425}},"7f0762d52579469dbe161c4631f46f7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f38df42c483403dbb664c56091adb5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f519e4eb044532be1e04e36cc0214f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8469a71422024eaabdbfd04de97e0ca0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86cad67f6e794efe832d59ddd819ee1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ac88d9a788432387617ab8a1f8eb81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"891ac8ae7fe2427eb4193ad8a3a8c988":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d553fbdcae474cbcaa52d320448c5ebc","IPY_MODEL_dc78e90e846945f8b9fac6d0f2a599a6","IPY_MODEL_789215b74b864eeb902f454722716792"],"layout":"IPY_MODEL_913341fd949148749656968aaf4c4c31"}},"8a5cadc329bf4da8980a9696e54577d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8abcaabacf594539b6249d4e9e4f9ddf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c26597f3c3e4667bbdd6afa13e5e4fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae676f6f99f4f4995d10fcce6804440","max":22458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a95cda38e8b24c75957fed6144b2b622","value":22458}},"8cbfde68f83e4a0e88ef3d0dda783408":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913341fd949148749656968aaf4c4c31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93546135280e40918b50d35d43f86b37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96cf6557c162480d9ac27a87bd6d3800":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a2bd5bcb3714d5da9887a964bd49dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b3a6baa5ff64fdbb7b86c2b0bb940b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe5f0712bb724f858575ab3a6be0f7ae","placeholder":"​","style":"IPY_MODEL_e389c53ba7fb41239b30e751572f4b7e","value":" 425/425 [00:00&lt;00:00, 40.0kB/s]"}},"9f97adb5755a491586fc3ac8a8d64dcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a22cb1bdfa1a468aa0a3bcf83e7af7a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49e5e8bf54f4494f9713d3b7dd13b856","placeholder":"​","style":"IPY_MODEL_14fb0748a60b40908761eca37bd17a32","value":"Generating validation split: 100%"}},"a333e0dd584e4bb2aae21b1d7739b47d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a922d1d72bee470fbda5fa8bae602421":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a95cda38e8b24c75957fed6144b2b622":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9e0deaec6a74f36893927978d91d1a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaebd545194c4598a2aeab4b52638d44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adcc65538b0c4933bb942df1c868c3dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aed3b1958dda467baa7e42ce595a09e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f97d36f501bb46ecaffaec81a9bea080","IPY_MODEL_be6bbb42ea2a4a00b573fcc8c73f580c","IPY_MODEL_51345c71cb0240f78abfdb6c2dea2194"],"layout":"IPY_MODEL_73fda8d877cc46e1a32cc688bddab7ce"}},"b1769221179c40dab957ef0ed9d76526":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15d6556839a41199422b19ddd925a43","placeholder":"​","style":"IPY_MODEL_2b049029bd044fd2be6f0bf72ac64edf","value":"vocab.txt: 100%"}},"b4ed130b9920481a84c44924af691dce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc9689399805461481b7a6db9ed6bfbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be6bbb42ea2a4a00b573fcc8c73f580c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a7aa75a72ae4201975ec315f645d537","max":4209983,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dbaa132b8cb4a5882020f4cf8896324","value":4209983}},"bffe4df19a85471f8f494dfeaa528f8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f126e8b11afb4b85a59a4a365068514e","placeholder":"​","style":"IPY_MODEL_9f97adb5755a491586fc3ac8a8d64dcb","value":"Downloading data: 100%"}},"c943bc7f00f544c48afa21df8bdc77cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cff18aae18814fcfae52846a1411099b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1769221179c40dab957ef0ed9d76526","IPY_MODEL_7240c5704ff64d45bc1a71d4a204a6c5","IPY_MODEL_52f334fdfd6b4f3c880c17d8961791c1"],"layout":"IPY_MODEL_7237a0e7878946559daa2653c27e247c"}},"d38d551358964724b3de2ae5dd1f6af3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d553fbdcae474cbcaa52d320448c5ebc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc8c0a38c663491dabd36e03ac49be3c","placeholder":"​","style":"IPY_MODEL_56844b8157a54ef88cb21b8d6433598f","value":"tokenizer_config.json: 100%"}},"d559ea1100de41a4a299e7613ecc69b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d67951876deb465095e67dee85dec734":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dada57c9c7ba489dbd7cd9ed30dac2a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c7674cf1fca4ffb877544cf0bfe0a09","IPY_MODEL_63d24a794ec24e16bc5ccd7339d23f31","IPY_MODEL_1e33ac94ae8747f69510d37490dd577e"],"layout":"IPY_MODEL_7f38df42c483403dbb664c56091adb5b"}},"dc78e90e846945f8b9fac6d0f2a599a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13451417ef224b2883e4d7685008e4c6","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46ec58009ee14c4e93418dc16c0f10e5","value":289}},"dc8c0a38c663491dabd36e03ac49be3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e389c53ba7fb41239b30e751572f4b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62a428f660a48b5b74d610dd163b986":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb64f4cdfa1f42e8abb88bd09fa55dcb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece8dfb733714d23a21090917df09124":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38d551358964724b3de2ae5dd1f6af3","placeholder":"​","style":"IPY_MODEL_5c5f116c98304e1cac473fa3005bf436","value":" 22.5k/22.5k [00:00&lt;00:00, 877kB/s]"}},"ed4d2bb0f55f43a8afe314e69103da4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee926ee0b7b048a384373926e7c872ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_332256d10c144eb0a2c13f3345aba99a","placeholder":"​","style":"IPY_MODEL_bc9689399805461481b7a6db9ed6bfbb","value":" 21008/21008 [00:00&lt;00:00, 72574.73 examples/s]"}},"eeea8078f9f94179aa12b0d1112b4608":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cc18342112b4e61bc01a0eb82703983","IPY_MODEL_7eb428de431d46fea5638628d762fef4","IPY_MODEL_9b3a6baa5ff64fdbb7b86c2b0bb940b7"],"layout":"IPY_MODEL_81f519e4eb044532be1e04e36cc0214f"}},"f0d7ad968e334ac5af1bbb829d76b887":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f126e8b11afb4b85a59a4a365068514e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15d6556839a41199422b19ddd925a43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7bf2e0ab8384b7ea0e8f982367b12a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_654d2a19b1fd407e8a33b726e8a323dd","placeholder":"​","style":"IPY_MODEL_687bcf468ca543c4a6352fe849c99a01","value":"Downloading readme: 100%"}},"f97d36f501bb46ecaffaec81a9bea080":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19d91af2a4f34f469becd27f55d84b9d","placeholder":"​","style":"IPY_MODEL_727eee58ef014b20952910c7c7e6424b","value":"Downloading data: 100%"}},"fae676f6f99f4f4995d10fcce6804440":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc3c0f1d87c14b318f392645aeb6162e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21ae61942ec843ce8186aae149f08e4b","placeholder":"​","style":"IPY_MODEL_8a5cadc329bf4da8980a9696e54577d0","value":"Generating train split: 100%"}},"fe5f0712bb724f858575ab3a6be0f7ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
